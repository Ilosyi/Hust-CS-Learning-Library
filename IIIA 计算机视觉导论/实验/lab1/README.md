# 基于前馈神经网络的二维高斯数据分类

本项目设计并实现一个前馈神经网络（Feedforward Neural Network, FNN），用于对一个四分类的二维高斯分布数据集进行分类。通过一系列对比实验，探索了不同网络架构、超参数和正则化方法对模型性能的影响，并最终确定了一套高效、简洁的优化配置。
@[TOC]
## 项目描述

[cite\_start]本项目的核心任务是解决一个多分类监督学习问题 [cite: 23][cite\_start]。具体而言，需要设计一个包含至少一层隐藏层的前馈神经网络，对一个包含4000个样本的数据集进行分类 [cite: 21, 22][cite\_start]。每个样本包含2个特征和1个类别标签（共4个类别） [cite: 21][cite\_start]。实验将数据集按90%训练集和10%测试集的比例划分，以评估模型的分类性能和泛化能力 [cite: 22]。

## 环境要求

[cite\_start]为保证实验的可复现性，建议在以下或相似环境中运行代码 [cite: 35]：

  - [cite\_start]**操作系统**: Windows 11 家庭版 [cite: 40]
  - [cite\_start]**Python**: 3.11.11 [cite: 41]
  - [cite\_start]**深度学习框架**: PyTorch 2.6.0 [cite: 42]
  - **核心依赖库**:
      - `pandas`
      - `numpy`
      - `scikit-learn`
      - `matplotlib`
  - **硬件 (可选，用于GPU加速)**:
      - [cite\_start]**显卡**: NVIDIA GeForce RTX 4070 Laptop GPU [cite: 36]
      - [cite\_start]**CUDA**: 12.3 [cite: 39]
  - [cite\_start]**开发工具**: Visual Studio Code (VSCode) [cite: 43]
  - [cite\_start]**环境管理**: Anaconda [cite: 44]

你可以通过以下命令安装主要依赖：

```bash
pip install torch pandas scikit-learn matplotlib
```

## 文件结构

```
.
├── main.py               # 主实验代码，包含数据处理、模型定义、训练、评估和可视化
├── dataset.csv           # 包含4000个样本的二维高斯数据集
├── experiment_log.csv    # (自动生成) 用于记录每次实验的配置和结果
└── README.md             # 本说明文档
```

[cite\_start]*报告中还提及了 `optimized_main.py`，它是一个集成了 `BatchNorm` 和可变 `Dropout` 的增强版本，用于进行更复杂的正则化实验 [cite: 64]。*

## 如何运行

1.  确保已安装所有[环境要求](https://www.google.com/search?q=%23%E7%8E%AF%E5%A2%83%E8%A6%81%E6%B1%82)中列出的依赖库。
2.  将 `dataset.csv` 文件放置在与 `main.py` 相同的目录下。
3.  在 `main.py` 文件顶部的 `CONFIG` 字典中，可以按需修改模型架构、学习率、批次大小等超参数。
4.  执行主脚本：
    ```bash
    python main.py
    ```
5.  脚本执行完毕后，将在控制台输出最终的评估结果，并弹出一个包含损失和准确率变化曲线的可视化窗口。同时，实验结果会被追加记录到 `experiment_log.csv` 文件中。

## 最佳模型配置

经过多组对比实验，最终确定了以下性能优异且结构简洁的配置：

  - [cite\_start]**网络架构**: `Input(2) -> Hidden(32, ReLU) -> Output(4)` [cite: 67]
  - [cite\_start]**超参数**[cite: 69]:
      - **学习率 (Learning Rate)**: 0.001
      - **批次大小 (Batch Size)**: 32
      - **训练轮数 (Epochs)**: 15
      - **优化器 (Optimizer)**: Adam
  - **正则化**:
      - [cite\_start]**Dropout**: 0.0 (由于模型简单，无需额外正则化) [cite: 69]

[cite\_start]该浅层网络仅包含164个参数，但已能达到极高的分类精度，证明了其高效性与强大的泛化能力 [cite: 70]。

## 实验结果

### 最终性能

[cite\_start]在最佳配置下，模型在测试集上表现出色，准确率高达 **99.75%**，甚至略高于训练集的 **98.69%**，表明模型泛化能力强，未出现过拟合现象 [cite: 119, 120]。

| 指标      | 训练集   | 测试集   |
| :-------- | :------- | :------- |
| **准确率** | 98.69%   | 99.75%   |
| **损失** | 0.0407   | 0.0263   |
[cite\_start]*数据来源: 实验报告 表3-1 [cite: 119]*

### 训练过程分析

  - [cite\_start]**快速收敛**: 模型在前5个epoch内收敛迅速，损失从0.86急剧下降至0.08，准确率从约92%提升至接近99% [cite: 124]。
  - [cite\_start]**无过拟合**: 在整个训练过程中，测试集的准确率始终与训练集持平或更高，损失曲线也基本重合，未出现明显分叉 [cite: 125, 127]。

### 对比实验结论

  - [cite\_start]**架构**: 对于此任务，浅层网络（如单隐藏层含16或32个神经元）已足够，其性能不亚于更深或更宽的网络，且参数更少、效率更高 [cite: 133]。
  - [cite\_start]**激活函数**: `ReLU` 和 `Sigmoid` 在该任务上表现最佳 [cite: 142, 153]。
  - [cite\_start]**优化器**: `Adam` 和 `SGD` 优化器的最终性能表现接近 [cite: 150]。
  - [cite\_start]**正则化**: 由于网络简单且数据线性可分性强，`Dropout` 和 `BatchNorm` 等正则化技术作用有限。但 `Dropout` 仍能有效降低测试损失，可作为稳定训练的补充手段 [cite: 149]。

## 可视化

[cite\_start]脚本运行结束后，会自动生成展示每个 mini-batch 训练后的损失和准确率变化曲线图，直观地反映了模型的整个学习过程 [cite: 126]。

  - [cite\_start]**左图 (Loss Curve)**: 展示了训练损失和测试损失随训练步数增加而迅速下降并趋于平稳的过程 [cite: 127]。
  - [cite\_start]**右图 (Accuracy Curve)**: 展示了训练和测试准确率随训练步数增加而快速上升并稳定在较高水平的过程 [cite: 127]。

[cite\_start]*图例：实验报告 图3-1 [cite: 126]*

## 未来可改进方向

[cite\_start]为进一步提升实验的深度和广度，报告中提出了以下改进方向 [cite: 155, 156, 157]：

1.  **结果可视化**: 绘制模型的**决策边界**和**混淆矩阵**，以更直观地分析其分类行为和易错点。
2.  **统计稳健性**: 通过设置**多次随机种子**重复实验，并报告性能的均值和方差，以增强结论的统计可靠性。
3.  **训练策略优化**: 引入**早停 (Early Stopping)** 机制防止不必要的训练，并使用**学习率调度器** (如 `CosineAnnealingLR`) 使训练过程更平滑高效。
4.  **模型可解释性**: 对困难样本进行分析，或通过 `PCA/UMAP` 等方法对隐藏层特征进行降维可视化，以探究模型的决策机制。
