#  第一章 绪论

## 一、操作系统与计算机体系结构的关系
### 1. 操作系统在计算系统中的地位
- **与硬件的关系**：控制CPU工作、访问存储器、处理中断、驱动设备，核心是高效利用硬件资源。
- **与用户及其他软件的关系**：对用户和软件进行控制与管理，提供便捷的用户界面和优质服务。
- **计算机系统组成**：硬件 → 操作系统 → 应用程序 → 用户。

# 2. 相互制约和限制
- **硬件对OS的限制**：提供OS运行的基础环境，同时限制OS的功能实现范围。
- **用户和上层软件的需求**：
  - 界面需求：图形界面、文本界面或无需交互。
  - 任务需求：单任务或多任务。
  - 交互需求：应用间的消息通讯与交互。
- 思考：硬件与软件相互影响、相互制约，并非单向决定关系。

### 3. 存储程序式计算机
- **特点**：
  - 由指令流驱动计算。
  - 集中顺序过程控制（集中：CPU集中管理；顺序：程序计数器控制；过程：模拟手工操作）。
- **核心矛盾**：顺序计算模型与现实世界问题的高并发模型不匹配。
- **架构对比**：
  - 冯·诺依曼模型（Von Neumann Model）：指令与数据共享存储器。
  - 哈佛模型（Harvard Model）：指令存储器与数据存储器分离。

## 二、操作系统的形成与发展
### 1. 手工操作阶段（1946~1960）
- **特点**：人工操作，作业独占计算机，串行执行。
- **核心问题**：人机速度不匹配，计算机性能提升后，人工操作成为效率瓶颈。
  | 机器速度 | 程序执行（计算）时间 | 人工操作时间 | 人工时间/计算时间 |
  |----------|----------------------|--------------|-------------------|
  | 1万次/秒 | 1小时                | 3分钟        | 1：20             |
  | 60万次/秒 | 1分钟                | 3分钟        | 3：1              |

### 2. 批处理阶段
#### （1）核心原理
将多个程序打包（batch），上一个程序执行完毕后，下一个程序自动运行，无需人工干预。

#### （2）出现的问题
CPU速度提升远超I/O速度，I/O操作成为新的效率瓶颈。

#### （3）<font color=crimson>多道程序设计技术（重点）</font>

- **定义**：主存中同时存放几道相互独立的程序，在系统控制下相互穿插运行；当某道程序因等待I/O等原因暂停时，调度另一道程序运行。

- **特征**：
  
  - 多道：内存中存在多个独立程序。
  - 宏观并行：程序相互穿插运行，看似同时进行。
  - 微观串行：CPU同一时刻仅执行单个程序。
  
- **物质基础**：足够容量的主存。

  <img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107033908327.png" alt="image-20251224193655892" style="zoom:50%;" />

**真题**：

1.在多道程序设计系统中，有 CPU、输入机、打印机，进程 A 先计算 50ms，再输入 80ms，再计算 100ms。进程 B 先计算 50ms，再打印 100ms，再计算 50ms。进程 A 先取得 CPU，进程 A 取得 CPU 时为 0 时刻

 (1) 绘制进程运行图。 CPU 输入机 打印机 时间轴————————————————————————————> 

 (2) 在两个进程执行过程中 CPU 是否有空闲？哪些时间段空闲？

 (3) 计算 CPU 利用率

答：

下面按**非抢占式 FCFS（先来先服务）**理解：进程在一次 CPU 计算段完成后才会让出 CPU；I/O 期间阻塞，CPU 可调度其它就绪进程。且 **A 在 0ms 先拿到 CPU**。

---

 (1) 进程运行图（甘特图）

 CPU

```makefile
时间(ms): 0        50       100      130                 230      280
CPU     : |   A    |   B    | idle   |         A          |   B    |
```

 输入机（Input）

```makefile
时间(ms): 0        50                130                              280
输入机  : | idle   |        A         |            idle               |
```

打印机（Printer）

```makefile
时间(ms): 0                 100               200                     280
打印机  : |      idle       |        B        |        idle            |
```

也可以用区间写清楚：

* **CPU**：A(0–50) → B(50–100) → 空闲(100–130) → A(130–230) → B(230–280)
* **输入机**：A(50–130)
* **打印机**：B(100–200)

---

 (2) CPU 是否空闲？哪些时间段空闲？

**有空闲。**
当 B 在打印（100–200）且 A 还在输入（50–130）时，**100–130ms** 两个进程都阻塞，CPU **空闲 30ms**。

---

 (3) CPU 利用率

* CPU 忙碌时间 = A 的 CPU(50+100) + B 的 CPU(50+50) = **250ms**
* 总完成时间 = 0 到全部结束 = **280ms**


$\text{CPU利用率}=\frac{250}{280}\approx 0.892857 \approx 89.29%$

✅ **CPU 利用率约为 89.29%**。




#### （4）执行系统

- **定义**：借助通道与中断技术，由主机控制I/O工作；监督程序常驻主存，兼具作业调度和I/O控制功能。
- **特点**：主机与外设并行操作，采用多道程序设计调度作业。
- **基本功能**：I/O控制、作业调度。
- **局限**：主机与外设的并行度有限，依赖程序运行特征。

#### （5）批处理分类
- **联机批处理**：作业输入/输出由主CPU处理，慢速I/O设备浪费主处理器时间。
- **脱机批处理**：引入卫星机（廉价处理器如MCU）负责I/O，主处理器仅与高速存储设备交互；是现代DMA（直接内存访问）技术的原型。

#### （6）主CPU与卫星机（MCU）对比
| 特性       | 主CPU（如AMD Ryzen R7、Intel Xeon E5） | MCU（如ESP32-S3、ARM Cortex-M0） |
|------------|----------------------------------------|----------------------------------|
| 应用范围   | 服务器、个人电脑                       | 嵌入式设备                       |
| 性能（Coremark） | 几千分~几万分                          | 100~2000分                       |
| 价格（RMB） | 几百块~几千块                          | 几块~几十块                      |

### 3. 分时系统阶段（1960~1970）
#### （1）时代背景
计算机价格昂贵，多个用户需共享单个计算机资源。

#### （2）分时技术定义
将处理机时间划分为短时间片（如几百毫秒），轮流分配给各个应用程序；若程序在时间片用完前未完成计算，则暂停执行，等待下一次分配时间片后继续。

### 4. 实时系统
- **定义**：能及时响应外部事件请求，在规定截止时间（deadline）内完成处理，并控制实时任务协调一致地运行。
- **分类**：
  - 硬实时系统：不满足实时约束会导致灾难性后果。
  - 软实时系统：不满足实时约束仅导致服务质量降级。

### 5. 衍生和多样化阶段
#### （1）嵌入式操作系统
- 适配资源受限环境（计算能力、能耗、网络连接受限）。
- 典型应用：掌上PDA、手机、微波炉、数字相机、自动售货机、工业自动化仪表、医疗仪器等。

#### （2）个人计算机操作系统
- 面向PC设计，算力一般，外设丰富，支持人机直接交互。
- 核心特点：单用户多任务环境，界面友好。

#### （3）网络操作系统
- 支持网络通讯协议，可通过网络实现资源远程访问。
- 核心特点：支撑Web、FTP等网络应用，安全性增强。

#### （4）分布式操作系统
- 分布式系统：多个分散处理单元经互连网络连接，各单元高度自治且协同工作，实现全局资源管理、任务动态分配和分布式程序并行运行。
- 核心特点：资源协调与调度、单一系统镜像（SSI）。

## 三、操作系统的定义与特点
### 1. 定义
操作系统（OS）是大型软件系统，负责计算机软、硬件资源的分配，控制和协调并发活动，为用户和其他软件提供便捷接口与环境，保障用户获得良好工作体验。

### 2. 核心特点
#### （1）并发（concurrency）
- 定义：两个或多个事件在同一时间间隔内发生。
- 与并行（parallel）的区别：
  - 并发：如“唱一句再吃一口”，事件交替进行（小明一边吃雪糕一边唱歌）。
  - 并行：如“同时吃雪糕和走路”，事件同时进行（小明一边吃雪糕一边走路）。
- 关系：并行（关联事件）往往意味着并发，但并发不一定是并行。
- OS职责：支持并协调并发事件或进程。

#### （2）共享（sharing）
- 定义：系统资源可供多个并发执行的进程共同使用。
- 共享方式：
  - 时分复用：如多道系统中，多个作业共享CPU（按时间分片分配）。
  - 空分复用：如内存中同时存放多道程序（按空间划分内存区域）。
- OS职责：实现、管理和协调进程对资源的共享。

#### （3）虚拟（virtualization）
- 定义：将一个物理实体转换为若干个逻辑对应物。
- 示例：
  - 多道技术：程序装入内存不同地址空间，使每个程序误以为独占内存。
  - 分时技术：CPU时间分片分配，使每个进程误以为独占CPU。
- OS职责：实现逻辑到物理的转换。

#### （4）不确定性（异步性，asynchrony）
- 定义：多个作业的执行顺序和单个作业的执行时间不确定。
- OS职责：协调异步活动，同时提升系统资源利用率。

## 四、操作系统的资源管理功能
### 1. 核心管理功能
1. 处理机管理
2. 存储器管理
3. 设备管理
4. 信息管理（文件系统管理）

### 2. 资源与功能模块对应关系
| 系统资源   | 操作系统功能模块 |
|------------|------------------|
| 处理机     | 处理机管理       |
| I/O设备    | 设备管理         |
| 软件资源   | 文件系统         |
| 存储器     | 存储器管理       |

## 五、重点总结
### 1. 重点概念
多道程序设计、分时技术、联机/脱机批处理、操作系统的定义与四大特点（并发、共享、虚拟、不确定）。

### 2. 核心理解
- 存储程序式计算机的结构和特点
- 操作系统的演化历史和分类
- 操作系统的基本功能

# 第二、三章 操作系统的物质基础、结构和用户接口
## 一、操作系统的物质基础
操作系统的运行依赖核心硬件机制提供支撑，核心包括CPU特权级、中断机制、时钟和DMA技术，是OS实现资源管理与隔离的基础。

### 1. <font color=Crimson>**CPU特权级**</font>
#### （1）设计目的
系统中存在管理程序（OS内核）和用户程序两类角色，二者职责差异显著，需通过区分处理器状态保护操作系统核心资源不被非法访问。

| 对比维度       | 管理程序（OS内核）                | 用户程序                          |
|----------------|-----------------------------------|-----------------------------------|
| 处理器资源控制 | 调度和控制程序的执行              | 被调度、被控制                    |
| 其他资源管理   | 管理系统全部资源（如内存、外设）  | 获得并有限使用系统分配的资源      |

#### （2）特权级分类
- **管态（supervisor mode，核态）**：
  - 操作系统管理程序执行时的状态，属于特权态。
  - 可使用全部指令（含特权指令）、访问全部系统资源（整个存储区域）。
- **用户态（user mode）**：
  - 用户程序执行时的状态，属于非特权态。
  - 禁止使用特权指令，不能直接取用资源和修改机器状态，仅允许访问自身存储区域。

#### （3）特权指令示例
I/O指令（如x86的in/out指令）、MMIO地址空间访问指令、改变机器状态寄存器（MSR）的指令。

#### （4）典型架构特权级示例
- Intel 80386：分为4级（Ring0~Ring3），Ring0为最高特权级（内核态），Ring3为最低特权级（用户态）。
- RISC-V：分为3级，用户模式（User）→ 监管模式（Supervisor，内核态）→ 机器模式（Machine，最高特权级），支持通过中断陷入切换至更高特权级，通过中断返回切换至低特权级。

### 2. 中断机制
#### （1）设计必要性
应用程序（用户态）需OS（内核态）提供“帮助”，例如：
1. 程序执行非法操作（如除零、非法内存访问），需OS干预；
2. 调用OS核心功能（如I/O操作，需内核态权限）；
3. 响应外部设备I/O事件（如键盘敲击、磁盘数据传输完成）。
中断的本质是**受保护的状态转换**，转换过程不允许用户程序干预，确保OS内核安全。

#### （2）中断响应的一般过程
中断处理分为硬件实现和软件实现两部分，流程闭环且隔离：
1. **中断进入（硬件实现）**：
   - 接收中断信号后，自动改变机器状态，从低优先级（如用户态）切换至高优先级（如核态）；
   - 硬件强制执行，不允许软件介入。
2. **中断处理（OS内核软件实现）**：
   - 保护应用程序执行现场（CPU通用寄存器内容）至特定内存区域；
   - 在高优先级状态下执行中断处理逻辑（如处理I/O完成事件、异常修复）；
   - 调用中断返回指令触发后续流程。
3. **中断返回（硬件实现）**：
   - 从特定内存区域恢复之前保存的执行现场；
   - 切换回中断发生前的优先级（如用户态）；
   - 硬件强制执行，不允许软件介入，程序继续执行。

#### （3）<font color=Crimson>中断分类及区别</font>
中断分为异常（Exception）、系统调用（Syscall）、中断请求（IRQ）三类，核心差异体现在产生原因、处理时机和返回地址：

| 对比维度       | Exception（异常）                  | Syscall（系统调用）                | IRQ（中断请求，外部中断）          |
|----------------|-----------------------------------|-----------------------------------|-----------------------------------|
| 产生原因       | 当前程序执行导致的同步事件        | 当前程序主动调用OS功能            | CPU外部设备产生的异步事件          |
| 处理时机       | 异常指令执行过程中                | 中断指令（如int/ecall）执行完成后  | 指令执行间隙（不打断当前指令）     |
| 返回地址       | 发生异常的那条指令（需重试/修复） | 下一条指令（正常继续执行）        | 下一条指令（正常继续执行）         |
| 示例           | 除零错、非法内存访问              | x86的int指令、RISC-V的ecall指令    | 敲击键盘、磁盘数据传输完成         |

#### （4）思考问题
中断的发生不一定导致处理器状态变化（例如某些特权级内的中断处理，无需切换特权态）。

### 3. 时钟
时钟是OS实现时间管理、任务调度的核心硬件，常见三类时钟硬件：

#### （1）可编程间隔定时器（Programmable Interval Timer，PIT）
- 硬件原理：基于晶体振荡器，计数器随每个脉冲递减，保持寄存器用于加载计数初始值。
- 工作模式：
  - One-shot mode（单次模式）：触发一次中断后停止，需重新配置；
  - Square-wave mode（方波模式）：周期性触发中断。
- 核心概念：时钟滴答（Clock tick），即周期性的时钟中断（间隔可通过编程设置）。
- 现代演进：高精度可编程间隔定时器（HPET，High Precision Event Timer），精度更高、功能更强。

#### （2）实时时钟（Real Time Clock，RTC）
- 特点：PC机断电后仍能保存时间，通过主板电池供电，通常与CMOS RAM集成（又称CMOS Timer）。
- 作用：系统启动时，OS可读取RTC时间并转换为基准时间对应的时钟滴答数，初始化系统时间。

#### （3）时间戳计数器（Time Stamp Counter，TSC）
- 特点：部分处理器（如Intel Pentium）内置的64位寄存器，每接收到一个振荡信号就递增一次。
- 作用：为OS提供高精度时间度量（如进程执行时间统计）。

### 4. DMA（直接内存访问）
#### （1）核心特点
- 数据传输过程无需CPU参与控制，由DMA控制器独立完成；
- 需中断支持（传输完成后通过中断通知CPU）；
- 要求用于DMA的内存地址必须连续；
- 传输过程占用总线资源。

#### （2）作用
解放CPU，避免CPU陷入低效的I/O数据拷贝（如磁盘与内存间的数据传输），提升系统整体吞吐量。

## 二、操作系统的结构
OS的结构设计决定了内核的稳定性、效率和可扩展性，核心分为三类结构：

### 1. 单一大内核（宏内核，Monolithic kernel）结构
- 设计思想：将所有操作系统组件（中断管理、进程管理、内存管理、设备管理、文件系统等）全部放入内核，均运行在内核态。
- 优点：系统结构简单，组件间通信直接，效率高。
- 缺点：内核体积庞大，耦合度高，单个组件故障可能导致整个内核崩溃。
- 示例：Linux操作系统。

### 2. 微内核（Microkernel）结构
- 设计思想：仅将OS核心组件（如进程调度、IPC通信、中断管理）放入内核（运行在内核态），外围组件（如文件系统、设备驱动）放在用户态运行。
- 优点：内核体积小、耦合度低，稳定性强（外围组件故障不影响内核）。
- 缺点：组件间需通过IPC（进程间通信）交互，存在通信开销，效率略低。
- 示例：MACH、GNU HURD、QNX、鸿蒙操作系统。

### 3. 伴生内核（外核，Exokernel）结构
- 设计思想：同一台机器上运行多个OS，一个为主OS，其余为伴生OS，伴生OS结构简单，依赖主OS管理底层资源。
- 优点：支持多执行环境隔离，适配虚拟化、容器等场景。
- 缺点：完整系统结构复杂，主OS与伴生OS协调成本高。
- 示例：PKE（OS实验系统）、云端虚拟机、Docker容器。

### 4. OS组件与计算机硬件的对应关系
| 计算机硬件组件 | 操作系统核心组件       |
|----------------|------------------------|
| CPU、内存      | 中断管理、进程管理、进程调度、内存管理 |
| 磁盘、其他外设 | 设备管理、文件系统     |

## 三、操作系统虚拟机
虚拟机通过抽象硬件或执行环境，实现多环境共享底层资源，核心思想是“通过增加一层间接性解决问题”。

### 1. 虚拟机的定义
将单个计算机的硬件抽象为多个独立执行部件，使多个不同执行环境能并行运行并共享相同硬件；通过CPU调度和虚拟内存技术，让进程误以为独占处理器和内存。

### 2. 虚拟机的分类及示例
| 虚拟机类型       | 核心功能                                                                 | 示例                                  |
|------------------|--------------------------------------------------------------------------|---------------------------------------|
| 指令集（ISA）虚拟机 | 在某一ISA环境（如x86）下，模拟另一套ISA的机器（如RISC-V）                | spike模拟器、qemu模拟器                |
| 操作系统（OS）虚拟机 | 在A操作系统环境中，创建B操作系统的独立执行环境                            | VMWare、Xen（虚拟化软件）、Docker（容器） |
| 库函数（API）虚拟机 | 模拟操作系统的用户态API（运行库函数接口），适配不同OS的应用程序运行        | Wine（Windows应用在Linux上运行）       |
| 语言（language）虚拟机 | 提供语言运行时环境（runtime），通过解释或JIT（即时编译）运行虚拟机指令，实现跨平台 | JAVA虚拟机（JVM）、Android ART、Waydroid |

## 四、操作系统的生成和启动
### 1. 操作系统的生成
本质是OS的安装过程，即将OS相关组件部署到启动装置（磁盘、tftp服务器目录等），需配置以下启动环境：
- Bootloader（如x86的MBR、UEFI）：引导内核启动的程序；
- OS内核：操作系统核心执行代码；
- 文件系统：存储系统文件和用户数据；
- 执行环境：如用户态库（lib）、运行时依赖。

### 2. 操作系统的启动流程
不同架构的启动流程存在差异，核心逻辑为“引导程序→内核初始化→用户环境准备”：
- x86机器（Linux）：BIOS/UEFI → Bootloader（如GRUB）→ 加载Linux内核 → 初始化内核组件 → 挂载根文件系统 → 启动用户进程（init/systemd）；
- RV64G机器（PKE）：固件引导 → Bootloader → 加载PKE内核 → 内核初始化 → 启动用户环境。

## 五、<font color=Crimson>程序的链接</font>
程序需经过编译（compile）和链接（link）过程才能生成可执行文件，链接的核心是解决程序依赖的外部函数/符号引用问题。

### 1. 链接的分类及原理
#### （1）静态链接（Static Linking）
- 原理：将程序依赖的外部函数（如库函数）直接链接到目标文件中，生成单一可执行文件（如a.out）。
- 优点：可执行文件不依赖外部函数库，单独运行即可。
- 缺点：冗余度高——若多个应用程序依赖同一库函数，每个可执行文件都会包含该函数的副本，浪费磁盘和内存空间。

#### （2）动态链接（Dynamic Linking）
- 原理：不将外部函数嵌入目标文件，仅在程序中记录依赖的函数名和引用入口，运行时由操作系统加载器（loader）查找并加载所需函数库（如.so文件），动态解析引用。
- 优点：节约磁盘/内存空间，可执行文件体积小；函数库更新后无需重新编译程序。
- 缺点：可执行文件运行依赖外部函数库，若库缺失或版本不兼容，程序无法运行。

### 2. 静态库与共享库对比
| 对比维度       | 静态库（Static Library，如.a文件） | 共享库（Shared Library，如.so文件） |
|----------------|-----------------------------------|-----------------------------------|
| 链接方式       | 编译时嵌入可执行文件              | 运行时动态加载解析                |
| 可执行文件依赖 | 无，包含库函数副本                | 有，需运行时找到对应库            |
| 磁盘/内存占用  | 较高（冗余副本）                  | 较低（共享同一库）                |
| 更新兼容性     | 库更新需重新编译程序              | 库更新无需重新编译程序（兼容版本） |

## 六、操作系统的用户接口
操作系统为用户和程序提供两类接口，是用户与OS交互、程序请求OS服务的核心途径。

### 1. 接口定义
用户接口是OS提供的外部机制，用户/程序可通过该机制控制系统、请求服务。

### 2. 接口分类
#### （1）操作界面（命令接口）
- 作用：用户用于组织工作流程、控制程序运行。
- 示例：
  - 字符命令接口：如Linux的Shell命令（ls、cd、mkdir）；
  - 图形用户接口（GUI）：如Windows的桌面、macOS的Finder，通过鼠标、图标交互。

#### （2）系统功能服务界面（程序接口）
- 作用：用户程序运行时，通过该接口请求OS的核心服务（如I/O、内存分配）。
- 核心实现：系统调用（syscall）——程序通过触发中断（如x86的int指令、RISC-V的ecall指令）从用户态陷入内核态，OS执行对应服务后返回结果。

## 七、重点总结
### 1. 必须掌握的核心知识点
- CPU特权级：管态/用户态的概念、设计目标、权限差异；
- 中断机制：中断的定义、分类（Exception/Syscall/IRQ）、响应流程；
- 程序链接：静态链接与动态链接的原理、优缺点、适用场景；
- 用户接口：操作接口与程序接口的区别，系统调用的概念及实现方式。

### 2. 需理解的关键内容
- 操作系统的物质基础：PIT、RTC、TSC时钟的功能，DMA的工作原理及作用；

- 操作系统的结构：宏内核、微内核、外核的设计思想、优缺点及典型示例；

- 虚拟机：虚拟机的核心概念、分类及应用场景；

- 系统生成与启动：启动环境的组成，启动流程的核心环节。


# 第四章 进程及进程管理
## 一、进程的引入
### 1. 顺序程序及特点
#### （1）核心概念
- 计算：程序的一次执行过程，由若干简单操作组成。
- 顺序执行：一个计算的所有操作需按严格先后次序依次执行。

#### （2）单道系统中的操作流程
对用户作业的处理分为三个顺序步骤：
- I（输入操作）：读取程序和数据；
- C（计算操作）：执行程序逻辑；
- P（输出操作）：打印计算结果。
单用户系统中，多个作业按“作业1的I→C→P”完成后，再执行“作业2的I→C→P”，操作完全串行。

#### （3）顺序程序的三大特点
- 顺序性：处理机严格按程序规定的顺序执行操作；
- 封闭性：程序执行过程中，计算结果不受外界因素干扰；
- 可再现性：执行结果仅与初始条件有关，与执行速度无关。

### 2. 并发程序及特点
#### （1）多道系统中的操作流程
多个用户作业的I、C、P操作可重叠执行，例如：
- 作业1执行C操作时，作业2可并行执行I操作；
- 作业1执行P操作时，作业2可并行执行C操作、作业3可并行执行I操作。

#### （2）并发执行的定义
若干个程序段同时在系统中运行，执行时间上存在重叠（一个程序段未结束，另一个已开始），称为并发执行。
- 并行语句记号：`cobegin S1; S2; …; Sn; coend`（S1~Sn为并发执行的程序段）。

#### （3）并发程序的三大特点
- 失去封闭性和可再现性：多个程序可能共享公共变量，一个程序的执行会改变另一个程序的变量，导致输出依赖于各程序的相对执行速度；
  - 示例：程序A（`n := n+1`）与程序B（`print(n); n := 0`）共享变量n（初值10），因执行顺序不同，可能出现打印结果为11、10等不同情况，n的最终取值也可能为0或1；
- 程序与计算不再一一对应：一个程序可对应多个计算（如C编译程序可同时编译多个源文件）；
- 存在相互制约关系：
  - 间接制约：因共享资源（如CPU、内存）产生的制约；
  - 直接制约：因共享公共变量（如协作完成任务的程序间）产生的制约。

### 3. 与时间有关的错误
程序并发执行时，若共享公共变量且未加控制，其执行结果与各进程的相对速度有关——即使初始条件相同，也可能得到不同结果，这种错误称为与时间有关的错误。
- 示例：程序A和B均执行`n := n+1`，共享变量n（初值0）。若A的“取n→加1→存n”未原子执行，可能出现A取n=0后，B也取n=0，最终n=1（而非预期的2）。

## 二、进程概念
### 1. 进程定义与与程序的区别
#### （1）进程定义
进程是一个程序在给定活动空间和初始环境下，在一个处理机上的执行过程（动态概念，存在“运行→暂停→运行”的状态变化）。

#### （2）进程与程序的核心区别
| 对比维度       | 进程（动态）                          | 程序（静态）                          |
|----------------|---------------------------------------|---------------------------------------|
| 本质属性       | 执行过程/活动单位                     | 指令集合/文件                          |
| 资源占用       | 竞争系统资源的基本单位                | 不占用系统资源（仅存储在磁盘）         |
| 对应关系       | 一个程序可对应多个进程（如记事本程序可打开多个窗口） | 一个进程至少包含一个程序               |
| 生命周期       | 有创建、运行、终止的完整生命周期      | 无生命周期，永久存在                   |

### 2. 进程的状态及变迁
#### （1）三个基本状态
- 运行状态（running）：已获得所有必需资源，程序正在处理机上执行；
- 就绪状态（ready）：已获得除CPU外的所有必需资源，一旦获得CPU，立即可以运行；
- 等待状态（wait）：因等待某一事件（如I/O完成、资源释放）暂时停止执行，即使获得CPU也无法运行。

#### （2）状态变迁及触发条件

<img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107033943646.png" alt="image-20251225180829892" style="zoom:50%;" />

#### （3）状态变迁的讨论
- 就绪→等待：一般不发生（就绪状态已具备除CPU外的所有资源，无需等待其他事件）；
- 等待→运行：个别系统支持（直接从等待状态被调度到运行状态，跳过就绪队列），多数系统需先进入就绪状态。

#### （4）多进程环境下的程序执行示例
- 示例1（三个排序程序）：
  - 不支持多进程OS：依次执行A、B、C，屏幕依次显示三个排序过程；
  - 支持多进程OS：创建进程A、B、C，采用时间片轮转调度，屏幕三个窗口同时显示排序过程（宏观并行，微观串行）；
- 示例2（打印程序C与计算程序D）：
  - 不支持多进程OS：先打印完报表，再执行计算，最后显示结果；
  - 支持多进程OS：C（I/O密集型）与D（计算密集型）并发执行，打印机持续打印，CPU同时进行计算。

### 3. 进程描述（PCB）
#### （1）进程的组成
进程由“程序与数据”和“进程控制块（PCB）”两部分组成：
- 程序与数据：描述进程需完成的功能（静态部分）；
- PCB：描述进程的动态特征（如状态、优先级），以及与其他进程、系统资源的关系（核心部分，进程存在的唯一标志）。

#### （2）PCB的主要内容
| 字段名称       | 功能描述                              |
|----------------|---------------------------------------|
| 进程标识符     | 进程符号名或内部ID（唯一标识进程）    |
| 进程当前状态   | 运行/就绪/等待（决定进程的调度优先级） |
| 当前队列指针   | 指向同一状态下的下一个进程PCB（用于组织进程队列） |
| 进程优先级     | 反映进程请求CPU的紧迫程度（调度依据） |
| CPU现场保护区  | 保存进程释放CPU时的寄存器内容（如程序计数器、通用寄存器），用于后续恢复执行 |
| 通信信息       | 进程间通信的相关记录（如消息队列指针） |
| 家族联系       | 指明父进程、子进程的PCB地址           |
| 占有资源清单   | 进程已占用的资源（如内存块、I/O设备） |

#### （3）进程队列的组织
OS通过PCB中的“队列指针”将同一状态的进程组织成队列：
- 就绪队列：所有就绪状态的进程PCB组成，按调度策略排序（如优先级、FIFO）；
- 等待队列：按等待事件分类（如打印机等待队列、I/O等待队列），每个队列包含等待该事件的所有进程PCB；
- 运行指针：指向当前运行进程的PCB（单CPU系统中仅有一个）。

## 三、进程控制
### 1. 进程控制的职责与原语
#### （1）核心职责
对系统中的进程实施有效管理，负责进程状态的改变（如创建、撤销、阻塞、唤醒）。

#### （2）常用控制原语
原语是不可分割的原子操作（执行过程中不被中断），包括：创建原语、撤销原语、阻塞原语（等待原语）、唤醒原语。

### 2. 进程创建（create原语）
#### （1）原语形式
`create(name, priority)`：name为进程标识符，priority为进程优先级。

#### （2）核心功能
创建一个指定标识符的进程，建立其PCB结构，具体步骤：
1. 检查PCB总链，判断是否存在同名进程（若有则出错返回）；
2. 从PCB资源池申请一个空的PCB；
3. 将进程名称、优先级等入口信息填入PCB；
4. 将PCB加入就绪队列和系统PCB总链；
5. 返回进程PID。

### 3. 进程撤销（kill/exit原语）
#### （1）原语形式
`kill()` 或 `exit()`：撤销当前运行的进程（或指定PID的进程）。

#### （2）核心功能
终止进程执行，释放资源，具体步骤：
1. 通过运行指针获取当前进程PID；
2. 释放进程占用的所有资源（如内存、I/O设备），归还父进程；
3. 将该进程PCB从总链队列中摘除；
4. 释放PCB结构到PCB资源池；
5. 转进程调度程序，选择下一个就绪进程执行。

### 4. 进程等待（susp原语）
#### （1）原语形式
`susp(chan)`：chan为进程等待的事件（如I/O完成、信号量）。

#### （2）核心功能
进程主动挂起自己，等待某事件发生，具体步骤：
1. 保护当前CPU现场（寄存器内容）到PCB的现场保护区；
2. 将进程状态设为“等待”；
3. 将PCB插入对应事件的等待队列；
4. 转进程调度程序，切换到其他进程执行。

### 5. 进程唤醒（wakeup原语）
#### （1）原语形式
`wakeup(chan)`：chan为进程等待的事件（与susp原语的chan对应）。

#### （2）核心功能
唤醒等待某事件的进程，具体步骤：
1. 找到对应事件的等待队列；
2. 将队列首进程的PCB移出等待队列；
3. 将进程状态设为“就绪”，并插入就绪队列；
4. 返回（若CPU空闲，触发进程调度）。

## 四、进程的相互制约关系
### 1. 进程互斥
#### （1）临界资源
一次仅允许一个进程使用的资源称为临界资源，包括：
- 硬件资源：打印机、输入机、磁带机等；
- 软件资源：公用变量、数据表格、队列等。

#### （2）临界区
进程中对公共变量进行审查与修改的程序段，称为相对于该临界资源的临界区（如对公用变量x执行`x := x+1`的程序段）。

#### （3）互斥的定义
当某一进程正在访问临界资源（执行临界区）时，其他进程不允许访问该资源（或执行对应的临界区），否则会导致数据不一致或错误，这种**相互制约关**系称为**互斥**。

### 2. 进程同步
#### （1）同步的定义
并发进程在关键节点上需互相等待与互通消息，以协调执行顺序，这种相互制约关系称为同步（协作关系）。

#### （2）同步示例
- 病员就诊：医生进程需等待化验进程完成并返回结果后，才能进行诊断；
- 共享缓冲区：计算进程（CP）将结果写入缓冲区，打印进程（IOP）需等待缓冲区有数据后才能读取打印；同时，CP需等待IOP取走数据（缓冲区为空）后才能写入下一个结果。

## 五、进程同步机构
### 1. 锁与上锁、开锁操作
#### （1）锁的定义
用变量w表示资源状态（w称为“锁”）：
- w=0：资源空闲（解锁状态）；
- w=1：资源被占用（上锁状态）。

#### （2）上锁与开锁操作
- 上锁操作：检测w的值，若w=1则循环等待；若w=0则置w=1，进入临界区；
- 开锁操作：临界区执行完毕后，置w=0，释放资源。

#### （3）原语实现
- 上锁原语`lock(w)`：
  ```
  {
      test: if (w == 1) goto test;  // 忙等
      else w = 1;                   // 上锁
  }
  ```
- 开锁原语`unlock(w)`：
  ```
  {
      w = 0;  // 开锁
  }
  ```

### 2. <font color=Crimson>**信号灯与P、V操作**</font>
#### （1）信号灯的定义
信号灯是二元组（s，q）：
- s：非负初值的整型变量（≥0表示绿灯，进程可执行；<0表示红灯，进程需等待）；
- q：初始为空的等待队列（存放因s<0而阻塞的进程）。
- 注意：信号灯初值不能为负，创建时需明确其意义（如互斥、同步）。

#### （2）P操作（申请资源）
- 定义：对信号灯s执行P(s)，不可分割的原子操作——s = s-1；若s≥0，进程继续执行；若s<0，进程阻塞并插入信号灯的等待队列q。
- 实现流程：
  1. 入口：s = s-1；
  2. 判断s≥0？若是，返回继续执行；若否，将进程置为“等待”状态，插入等待队列，转进程调度。

#### （3）V操作（释放资源）
- 定义：对信号灯s执行V(s)，不可分割的原子操作——s = s+1；若s>0，进程继续执行；若s≤0，唤醒等待队列q的首进程，将其插入就绪队列。
- 实现流程：
  1. 入口：s = s+1；
  2. 判断s≤0？若是，从等待队列取出首进程，置为“就绪”状态并插入就绪队列；
  3. 返回继续执行。

## 六、进程互斥与同步的实现
### 1. 用锁原语实现互斥
#### （1）核心逻辑
将临界资源的访问用“上锁-执行临界区-开锁”包裹，确保同一时间仅有一个进程进入临界区。

#### （2）程序描述
```c
main() {
    int w = 1;  // 互斥锁，初值1（资源空闲）
    cobegin
        pa();  // 进程A
        pb();  // 进程B
    coend
}

pa() {
    // 其他操作
    lock(w);    // 上锁
    csa;        // 进程A的临界区
    unlock(w);  // 开锁
    // 其他操作
}

pb() {
    // 其他操作
    lock(w);    // 上锁
    csb;        // 进程B的临界区
    unlock(w);  // 开锁
    // 其他操作
}
```

### 2. 用P、V操作实现互斥
#### （1）核心逻辑
设置互斥信号灯mutex（初值1），进程进入临界区前执行P(mutex)（申请资源），退出时执行V(mutex)（释放资源）。

#### （2）程序描述
```c
main() {
    int mutex = 1;  // 互斥信号灯，初值1
    cobegin
        pa();
        pb();
    coend
}

pa() {
    // 其他操作
    P(mutex);  // 申请临界资源
    csa;       // 临界区
    V(mutex);  // 释放临界资源
    // 其他操作
}

pb() {
    // 其他操作
    P(mutex);  // 申请临界资源
    csb;       // 临界区
    V(mutex);  // 释放临界资源
    // 其他操作
}
```

#### （3）信号灯取值含义（两进程互斥）
- mutex=1：无进程进入临界区；
- mutex=0：有一个进程进入临界区；
- mutex=-1：一个进程在临界区，另一个进程等待进入。

#### （4）示例（售票进程互斥）
```c
main() {
    int mutex = 1;  // 互斥信号灯，初值1
    int x = 10;     // 航班机座号，初值10
    cobegin
        pa();  // 售票进程A
        pb();  // 售票进程B
    coend
}

pa() {
    // 其他操作
    P(mutex);
    x = x + 1;  // 临界区（修改机座号）
    V(mutex);
    // 其他操作
}

pb() {
    // 其他操作
    P(mutex);
    x = x + 1;  // 临界区（修改机座号）
    V(mutex);
    // 其他操作
}
```

### 3. 用P、V操作实现同步
#### （1）合作进程的执行次序同步
- 示例：进程PA先执行，PA结束后PB、PC才能执行。
  - 信号灯设置：sb（控制PB，初值0）、sc（控制PC，初值0）；
  - 程序描述：
    ```c
    main() {
        int sb = 0, sc = 0;  // 同步信号灯，初值0
        cobegin
            pa();
            pb();
            pc();
        coend
    }
    
    pa() {
        // PA的操作
        V(sb);  // PA结束，允许PB执行
        V(sc);  // PA结束，允许PC执行
    }
    
    pb() {
        P(sb);  // 等待PA结束
        // PB的操作
    }
    
    pc() {
        P(sc);  // 等待PA结束
        // PC的操作
    }
    ```

#### （2）共享缓冲区的同步（单缓冲）
- 场景：计算进程CP向缓冲区写数据，打印进程IOP从缓冲区读数据。
  - 同步关系：CP需等待缓冲区为空（IOP取走数据），IOP需等待缓冲区有数据（CP写入）；
  - 信号灯设置：sa（表示缓冲区有数据，初值0）、sb（表示缓冲区为空，初值1）；
  - 程序描述：
    ```c
    main() {
        int sa = 0, sb = 1;  // sa：有数据；sb：有空位
        cobegin
            cp();
            iop();
        coend
    }
    
    cp() {
        while (计算未完成) {
            产生计算结果；
            P(sb);          // 申请空缓冲区
            将数据写入缓冲区；
            V(sa);          // 通知IOP有数据
        }
    }
    
    iop() {
        while (打印未完成) {
            P(sa);          // 等待缓冲区有数据
            从缓冲区取数据；
            V(sb);          // 通知CP缓冲区为空
            打印数据；
        }
    }
    ```

### 4. 生产者-消费者问题（经典同步问题）
#### （1）问题描述
m个生产者（不断生产产品）和k个消费者（不断消费产品）共享一个有n个缓冲区的有界缓冲区，需满足：
- 生产者不能向满缓冲区写产品；
- 消费者不能从空缓冲区读产品；
- 同一时间仅有一个进程（生产者/消费者）访问缓冲区。

#### （2）信号灯设置
- 同步信号灯：sb（空缓冲区数，初值n）、sa（满缓冲区数，初值0）；
- 互斥信号灯：mutex（保护缓冲区访问，初值1）。

#### （3）程序描述
```c
main() {
    int sa = 0, sb = n, mutex = 1;  // sa：满缓冲；sb：空缓冲；mutex：互斥
    cobegin
        p1(); p2(); ... pm();  // m个生产者
        c1(); c2(); ... ck();  // k个消费者
    coend
}

pi() {  // 生产者进程
    while (生产未完成) {
        生产一个产品；
        P(sb);          // 申请空缓冲区
        P(mutex);       // 申请访问缓冲区
        将产品放入缓冲区；
        V(mutex);       // 释放缓冲区访问权
        V(sa);          // 通知消费者有产品
    }
}

cj() {  // 消费者进程
    while (消费未完成) {
        P(sa);          // 等待有产品
        P(mutex);       // 申请访问缓冲区
        从缓冲区取产品；
        V(mutex);       // 释放缓冲区访问权
        V(sb);          // 通知生产者有空位
        消费产品；
    }
}
```

#### （4）关键注意事项
- P操作顺序不能颠倒：生产者需先申请空缓冲区（P(sb)），再申请互斥锁（P(mutex)）；若先申请互斥锁，可能导致生产者持有锁但无空缓冲区，阻塞后消费者无法获取锁，引发死锁；
- V操作顺序可颠倒：释放互斥锁（V(mutex)）和通知同步信号（V(sa)/V(sb)）的顺序不影响正确性。

### 5. 理发师问题（经典同步问题）
#### （1）问题描述
- 理发店有1名理发师、1间工作室（1把椅子）、n把接待室椅子；
- 无顾客时，理发师睡觉；
- 顾客到来时：若理发师睡觉则唤醒他；若理发师忙且接待室有椅子则等待；若接待室满则离去。

#### （2）信号灯设置
- 互斥信号灯：mutex（保护wating，初值1）；
- 同步信号灯：server（理发师空闲，初值0）、customer（有顾客等待，初值0）；
- 变量：wating（ 正在等待的顾客数量，初值0）。

#### （3）程序描述
```c
信号量 customer = 0; // 顾客资源数
信号量 server = 0; // 服务人员资源数
信号量 mutex = 1;
int waiting = 0; // 正在等待的顾客数量

Server(){
    while(1){
        P(customer); 
        P(mutex); //
        叫号;
        waiting--;
        V(mutex); //
        V(server);
        提供服务;
    }
}

Customer(){
    P(mutex); //
    if (waiting < n){
        取号;
        waiting++;
        V(mutex); //
        V(customer);
        P(server);
        被服务;
    }
    else{
        V(mutex);
        离店;
    }
}

```

### 6. 读者-写者问题（经典同步问题）
#### （1）问题描述
共享数据区支持多个读者（只读）和多个写者（只写），约束：
- 多个读者可同时读；
- 一个写者独占数据区（写时无读者/其他写者）；
- 写者与读者互斥。

#### （2）读者优先解法
- 信号灯设置：x（保护readcount变量，初值1）、wsem（写者互斥，初值1）；
- 变量：readcount（当前读者数，初值0）；
- 程序描述：
  ```c
  main() {
      int readcount = 0;
      semaphore x = 1, wsem = 1;
      cobegin
          reader();
          writer();
      coend
  }
  
  reader() {
      while (true) {
          P(x);          // 保护readcount
          readcount++;
          if (readcount == 1) {
              P(wsem);  // 第一个读者申请写者互斥
          }
          V(x);          // 释放readcount保护
          读数据；
          P(x);          // 保护readcount
          readcount--;
          if (readcount == 0) {
              V(wsem);  // 最后一个读者释放写者互斥
          }
          V(x);          // 释放readcount保护
      }
  }
  
  writer() {
      while (true) {
          P(wsem);  // 申请写权限
          写数据；
          V(wsem);  // 释放写权限
      }
  }
  ```
- 问题：读者持续到来时，写者可能长期等待（饥饿）。

#### （3）写者优先解法（思路）
增加写者等待信号灯，当有写者申请时，阻止新读者进入，优先唤醒写者。

### 7. 进程通信
进程通信是进程间直接传递较多数据的高效交互方式，主要包括：
- 消息缓冲通信：通过消息缓冲区传递消息，提供发送原语（send）和接收原语（receive）；
- 信箱通信：通过信箱（用户空间/OS空间）传递消息，需定义信箱结构、发送/接收原语，支持同步/异步通信。

## 七、线程
### 1. 线程定义
线程是比进程更小的活动单位，是进程中的一条执行路径，具有：
- 私用栈和处理机执行环境；
- 与同一进程的其他线程共享进程的主存空间和资源（如文件描述符、信号量）。

### 2. 线程的特点
- 创建开销小：线程无需独立分配资源，仅需创建私用栈和执行环境，比进程创建快得多；
- 通信便捷：同一进程的线程共享地址空间，可直接访问共享数据，无需复杂的进程间通信机制；
- 动态性：具有生命周期（创建、就绪、运行、等待、终止）；
- 提高并行性：进程内多线程可并发执行，充分利用CPU资源（如I/O密集型进程的线程在等待I/O时，其他线程可继续执行）。

### 3. 线程的状态变迁
线程的状态与进程类似，包括：创建→就绪→运行→等待→终止，状态变迁触发条件与进程一致（如时间片到、I/O请求、唤醒等）。

## 八、进程调度
### 1. 调度与分派的概念
- 调度：从就绪队列中按一定策略选择一个进程；
- 分派：将CPU分配给选中的进程，使其从就绪状态转为运行状态。

### 2. 进程调度的功能
- 维护进程管理数据结构（就绪队列、等待队列、PCB等）；
- 确定调度策略（如优先级调度、时间片轮转）；
- 实施CPU的分配与回收（上下文切换：保存当前进程现场，恢复选中进程现场）。

### 3. 调度方式
#### （1）非剥夺方式（非抢占式）
- 定义：若有高优先级进程到来，当前运行进程继续执行，直到完成或进入阻塞状态，才释放CPU给高优先级进程；
- 优点：实现简单，无上下文切换开销；
- 缺点：低优先级进程可能长期占用CPU，高优先级进程等待。

#### （2）剥夺方式（抢占式）
- 定义：若有高优先级进程到来，立即暂停当前运行进程，将CPU分配给高优先级进程；
- 优点：高优先级进程响应快，系统吞吐量高；
- 缺点：上下文切换开销大，可能导致低优先级进程饥饿。

### 4. 常用调度算法
#### （1）进程优先数调度算法
- 核心逻辑：按进程优先级（优先数）选择就绪队列中优先级最高的进程执行；
- 优先数分类：
  - 静态优先数：进程创建时确定，运行期间不变（如按进程类型、资源需求、估计运行时间确定）；
  - 动态优先数：运行期间动态调整（如CPU使用超时则降低优先级，I/O完成后提高优先级，等待时间过长提高优先级）。

#### （2）循环轮转调度算法（RR）
- 核心逻辑：
  1. 就绪队列按FIFO排序；
  2. CPU空闲时，选择队首进程，分配一个时间片（q）；
  3. 时间片用完，进程转为就绪状态，插入队列末端；
  4. 重复步骤2-3；
- 时间片计算：q = t/n（t为系统响应时间，n为就绪进程数）；
- 发展：可变时间片轮转（根据进程类型调整时间片）、多重时间片循环（多个就绪队列，不同队列时间片不同）。

### 5. 调度用的进程状态变迁示例
#### （1）状态定义
- 运行状态、高优先就绪状态、低优先就绪状态、因I/O而等待状态；
- 队列：高优先就绪队列、低优先就绪队列、I/O等待队列。

#### （2）调度算法
优先调度+时间片轮转结合：
- CPU空闲时，先从高优先就绪队列选进程，分配时间片100ms；
- 高优先队列为空时，从低优先就绪队列选进程，分配时间片500ms；
- 高优先级进程（如I/O密集型）响应快，低优先级进程（如计算密集型）获得较长时间片。

#### （3）状态变迁触发条件
- 高优先就绪→运行：高优先队列非空，CPU空闲；
- 低优先就绪→运行：高优先队列为空，CPU空闲；
- 运行→高优先就绪：时间片到（高优先级进程）；
- 运行→低优先就绪：时间片到（低优先级进程）；
- 运行→I/O等待：进程请求I/O；
- I/O等待→高优先就绪：I/O完成（I/O密集型进程，优先调度）。

## 九、重点总结
### 1. 核心概念（重点掌握）
- 进程的相互制约关系（重点掌握）
	- 进程互斥：临界资源、互斥、临界区
	- 进程同步：进程同步的概念、进程同步的例子

- 进程同步机构：锁、上锁原语、 开锁原语信号灯及P、V操作

- 进程同步与互斥的实现：
	- 用信号灯的P、V操作实现进程互斥
	- 两类同步问题的解答：合作进程的执行次序、共享缓冲区的合作进程的同步
	- 生产者-消费者问题及解答
	- 读者-写者问题及解答

### 2. 核心概念（掌握）
- 进程概念（掌握）
	- 进程引入
	  程序的顺序执行    定义  特点
	  程序的并发执行    定义  特点
	- 进程定义
	定义
	进程与程序的区别
	- 进程状态
	三个基本状态、状态变迁图
	不同操作系统类型的进程状态变迁图
	- 进程描述
	PCB的定义与作用
	进程的组成
	- 线程定义


- 操作系统的并发控制机制（掌握）
	- 创建进程、创建线程及其使用
	- 等待进程、线程的终止及其使用 
	- 信号量与使用方法
	- 共享内存与使用方法
- 进程调度（掌握）
	- 进程调度的功能
	- 调度方式   非剥夺方式   剥夺方式
	- 常用的进程调度算法
	- 调度用的进程状态变迁图的分析


### 3. 关键注意事项
- 并发程序的“与时间有关的错误”：源于共享变量的非原子操作；
- P、V操作的顺序：同步P操作需在互斥P操作之前，避免死锁；
- 调度算法的权衡：响应时间、吞吐量、公平性、饥饿问题。

## 真题：

使用 PV 信号灯描述下列进程 P1,P2,P3,P4 的并发与同步。有一大小为 的缓冲区，P1,P2 使用 gen() 函数生成随机正整数，使用 put() 函数将其放入缓冲区。P3 使用 getodd() 函数获取缓冲区中 的奇数，P4 使用 geteven() 获取缓冲区中的偶数。使用伪代码描述，信号灯需标明含义。

答：下面给出一种**用 PV 信号灯**实现 P1、P2（生产者）与 P3（取奇数）、P4（取偶数）之间**并发与同步**的经典做法。设缓冲区容量为 **N**（题目里“大小为 ___ 的缓冲区”记为 N）。

---

### 信号灯定义（并标明含义与初值）

```c
semaphore mutex = 1;      // 互斥进入缓冲区临界区（保护缓冲区结构/数据）
semaphore empty = N;      // 缓冲区空槽数（还剩多少位置可放）
semaphore odd  = 0;       // 缓冲区内“奇数”资源数（可供 P3 取的奇数个数）
semaphore even = 0;       // 缓冲区内“偶数”资源数（可供 P4 取的偶数个数）
```

---

### 缓冲区操作约定（伪代码）

* `put(x)`：把 x 放入缓冲区某个空槽
* `getodd()`：从缓冲区**取走并删除一个奇数**
* `geteven()`：从缓冲区**取走并删除一个偶数**

> 关键点：`getodd/geteven` 在 `mutex` 保护下执行，可以在缓冲区里扫描找到符合条件的元素并删除（不要求 FIFO）。

---

### 进程伪代码

#### P1 / P2：生产者（两者相同）

```c
process P1 (同 P2) {
    while (true) {
        x = gen();                 // 生成随机正整数

        P(empty);                  // 先确保有空槽
        P(mutex);                  // 进入临界区

        put(x);                    // 放入缓冲区

        if (x % 2 == 1) V(odd);    // 增加“可取奇数”计数
        else            V(even);   // 增加“可取偶数”计数

        V(mutex);                  // 退出临界区
    }
}
```

#### P3：只取奇数

```c
process P3 {
    while (true) {
        P(odd);                    // 没有奇数就睡眠等待
        P(mutex);                  // 进入临界区

        x = getodd();              // 取走一个奇数（并从缓冲区删除）

        V(mutex);                  // 退出临界区
        V(empty);                  // 释放一个空槽

        // 使用 x ...
    }
}
```

#### P4：只取偶数

```c
process P4 {
    while (true) {
        P(even);                   // 没有偶数就睡眠等待
        P(mutex);                  // 进入临界区

        x = geteven();             // 取走一个偶数（并从缓冲区删除）

        V(mutex);                  // 退出临界区
        V(empty);                  // 释放一个空槽

        // 使用 x ...
    }
}
```

---

### `getodd()` / `geteven()`（示意实现）

只要保证在 `mutex` 临界区内执行即可。比如用“扫描 + 删除”：

```c
int getodd() {
    for (i = 0; i < N; i++) {
        if (slot[i].full && slot[i].value % 2 == 1) {
            x = slot[i].value;
            slot[i].full = false;
            return x;
        }
    }
}
```

```c
int geteven() {
    for (i = 0; i < N; i++) {
        if (slot[i].full && slot[i].value % 2 == 0) {
            x = slot[i].value;
            slot[i].full = false;
            return x;
        }
    }
}
```

---

### 同步关系总结（你写答案时可直接用）

* `empty` 保证 **缓冲区不溢出**：生产者放之前必须 `P(empty)`，消费者取后 `V(empty)`。
* `odd / even` 保证 **按奇偶正确唤醒**：

  * 生产者放入奇数就 `V(odd)`，放入偶数就 `V(even)`；
  * P3 先 `P(odd)`，P4 先 `P(even)`，因此不会“取不到对应类型还硬取”。
* `mutex` 保证 **对缓冲区的互斥访问**：`put/getodd/geteven` 不会并发破坏缓冲区结构。

如果你希望缓冲区必须严格 FIFO（而 `getodd/geteven` 又要按奇偶取），那就需要更复杂的队列/重排策略；但题目只说“从缓冲区获取奇数/偶数”，上述方案是最常用、最直接的 PV 解法。


# 第五章 资源分配与调度
## 一、资源管理概述
### 1. 核心管理功能
- 资源数据结构描述：记录资源的物理名、逻辑名、类型、地址、分配状态等关键信息。
- 确定资源分配原则：明确资源分配的对象、时机和数量。
- 实施资源分配与回收：执行资源的分配操作，以及进程结束后资源的回收工作。
- 存取控制与安全保护：对资源的存取进行控制并对资源实施安全保护措施

### 2. 资源分配方式
#### （1）静态分配
- 适用层级：作业级分配。
- 分配逻辑：调度作业时，根据作业所需资源一次性分配全部资源；作业运行完毕后，收回所有分配的资源。
- 特点：资源分配后全程占用，不会出现动态申请导致的冲突，但资源利用率较低。

#### （2）动态分配
- 适用层级：进程级分配。
- 分配逻辑：进程运行过程中，根据其动态提出的资源需求，实时分配资源；进程使用完毕后即时回收，资源可重复利用。
- 特点：资源利用率高，但需解决分配冲突和死锁问题。

### 3. 物理资源与虚拟资源
#### （1）核心概念
- 物理资源（实资源）：计算机硬件提供的实际资源（如CPU、物理内存、外部设备）。
- 虚拟资源（逻辑资源）：OS通过抽象、映射技术构建的逻辑资源（如虚拟内存、逻辑设备）。

#### （2）设计目的
- 简化用户操作：用户无需关注物理资源的具体细节，通过统一的逻辑接口使用资源。
- 提高资源利用率：通过动态分配、复用等技术，让有限的物理资源支持更多用户/进程。

#### （3）各类资源的物理与虚拟映射关系
| 资源类别 | 物理资源                | 虚拟（逻辑）资源          | 映射方式                  |
|----------|-------------------------|---------------------------|---------------------------|
| 处理机   | CPU                     | 逻辑处理器（进程/线程）   | 进程调度（时间片轮转、优先级调度） |
| 存储器   | 主存（物理内存）        | 虚存（程序地址空间）      | 地址映射（分页、分段）    |
| 设备     | 外部设备（打印机、磁盘） | 逻辑设备、虚拟设备        | 设备分配、动态映射（如SPOOLing） |
| 信息     | 文件物理结构（磁盘块）  | 文件逻辑结构（文件名、路径） | 磁盘空间分配、文件目录查找 |

## 二、资源分配的机构和策略
### 1. 资源分配机构
#### （1）资源描述器（rd）
- 定义：描述各类资源最小分配单位的数据结构（如主存分区分配中，最小单位是主存分区）。
- 核心内容：资源名、资源类型、最小分配单位大小、物理地址、分配标志（已分配/空闲）、描述器链接信息、存取权限、密级、存取时间。

#### （2）资源信息块
- 定义：描述某类资源整体信息的数据结构，包含请求者、可用资源及分配程序等关键信息。
- 核心内容：
  - 请求者队列：等待该类资源的进程队列（含队列头指针）；
  - 可利用资源队列：空闲的该类资源队列（含队列头指针）；
  - 资源分配程序：负责该类资源分配的程序入口地址。

#### （3）示例：中央处理机资源信息块
- 组成：
  - 可用处理机信息：当前空闲的CPU数量及状态；
  - 请求者队列（ready_q_start）：就绪状态的进程PCB队列；
  - 资源分配程序入口（scheduler_addr）：进程调度程序的地址。

### 2. 资源分配策略
#### （1）先请求先服务（FIFO）
- 排序原则：按资源请求的先后次序排列请求队列。
- 分配逻辑：新请求加入队尾；资源可用时，优先满足队首请求。
- 特点：实现简单，公平性好，但可能导致“短请求等待长请求”，效率较低。

#### （2）优先调度
- 排序原则：按进程优先级高低排列请求队列。
- 分配逻辑：新请求按优先级插入队列对应位置（高优先级在前）；资源可用时，满足队首高优先级请求。
- 特点：优先响应紧急进程，提高系统吞吐量，但低优先级进程可能饥饿。

#### （3）针对设备特性的调度策略（以磁盘为例）
- 调度目标：减少大量I/O请求的总服务时间，核心优化磁盘访问的“移臂时间”和“旋转时间”。
- 磁盘访问请求的关键参数：柱面号（决定移臂距离）、盘面号、块号（决定旋转距离）。

##### ① 移臂调度
- 核心逻辑：选取当前移动臂前进方向上最近的I/O请求，最小化移臂距离。
- 示例：5个磁盘请求（柱面号：5、5、5、40、2），当前移臂方向从低柱面到高柱面，调整后顺序为：2→5→5→5→40。

##### ② 旋转调度
- 核心逻辑：移臂到位后，选取当前读写头最近的I/O请求，最小化旋转圈数。
- 示例：柱面号5的3个请求（块号：1、8、5），调整后顺序为：1→5→8（按块号递增，匹配磁盘旋转方向）。

## 三、死锁
### 1. 死锁的定义与示例
#### （1）定义
两个或多个并发进程，每个进程持有部分资源，同时等待其他进程释放已占用的资源，导致所有进程无法继续推进的僵持状态。

#### （2）经典示例：设备共享死锁
- 场景：进程p1、p2共享打印机（r1）和输入机（r2）。
  - 时刻t1：p1占用r1，p2占用r2；
  - 时刻t2：p1请求r2，p2请求r1；
  - 结果：双方互相等待对方释放资源，陷入死锁。

#### （3）信号灯描述死锁
- 信号灯设置：s1（表示r1可用，初值1）、s2（表示r2可用，初值1）。
- 死锁场景（程序描述2）：
  ```c
  // 进程p1                // 进程p2
  P(s1);  // 占用r1         P(s2);  // 占用r2
  P(s2);  // 请求r2         P(s1);  // 请求r1
  // 执行操作               // 执行操作
  V(s2);  // 释放r2         V(s1);  // 释放r1
  V(s1);  // 释放r1         V(s2);  // 释放r2
  ```
- 关键问题：进程请求资源的顺序不当，形成循环等待。

### 2. 死锁的起因和必要条件
#### （1）起因
- 系统资源不足：资源数量无法满足所有进程的需求；
- 进程推进顺序非法：进程请求和释放资源的顺序不符合安全规则（如循环请求）。

#### （2）必要条件（四个条件同时满足才会发生死锁）
- 互斥条件：资源是临界资源，一次仅允许一个进程使用；
- 不剥夺条件：进程已获得的资源，未使用完毕前不能被强行夺走；
- 部分分配（请求与保持）：进程每次申请部分资源，等待新资源时不释放已占用资源；
- 环路条件：存在进程循环链，链中每个进程已占有的资源被下一个进程请求。

### 3. 死锁的处理策略
#### （1）死锁预防（Prevent）
- 核心思想：破坏死锁的四个必要条件之一，从根源上避免死锁发生（静态策略）。

##### ① 破坏互斥条件
- 逻辑：将临界资源转化为共享资源（如SPOOLing技术，将打印机转化为“虚拟打印机”，多进程可同时提交打印请求）。
- 缺点：并非所有临界资源都能转化为共享资源（如物理内存），应用场景有限。

##### ② 破坏不剥夺条件
- 方案1（改造申请者）：进程请求新资源失败时，主动释放已占用的所有资源，后续需重新申请全部资源；
- 方案2（改造占用者）：OS可强行剥夺某进程的资源，分配给优先级更高的进程；
- 缺点：实现复杂，可能导致进程反复申请释放资源（效率低），或出现活锁。

##### ③ 破坏部分分配条件（静态资源分配法）
- 逻辑：进程运行前一次性申请所需的全部资源，资源未满足前不启动；运行期间不再申请新资源。
- 优点：简单易实现，彻底避免部分分配导致的死锁；
- 缺点：资源利用率极低（进程可能长时间占用未使用的资源），可能导致进程饥饿。

##### ④ 破坏环路条件（有序资源分配法）
- 逻辑：给系统中所有资源分配唯一编号，进程必须按资源编号递增的顺序申请资源。
- 示例：打印机（编号1）、输入机（编号2），进程需先申请1再申请2，避免循环请求；
- 缺点：用户编程需遵循资源编号顺序，灵活性差；进程实际使用资源的顺序可能与编号不一致，造成资源浪费。

#### （2）死锁避免（Avoid）
- 核心思想：允许死锁的必要条件存在，但在资源分配时动态判断“分配后系统是否安全”，仅当安全时才分配（动态策略）。

##### ① 关键概念：安全状态
- 定义：存在一个进程执行序列，使得每个进程都能获得所需资源并完成执行，最终释放所有资源，系统无死锁风险。
- 安全状态是避免死锁的核心：系统始终保持在安全状态，即可避免死锁。

##### ② <font color=Crimson>**银行家算法（经典避免算法）**</font>
- 核心逻辑：进程事先声明对各类资源的最大需求量，OS在分配资源时检查：若分配后系统仍为安全状态，则分配；否则拒绝。

##### ③ 算法示例
- 系统资源：某类资源共10个；
- 进程需求与占有：
  | 进程 | 最大需求量 | 已占有资源 | 剩余需求（最大-已占有） |
  |------|------------|------------|------------------------|
  | P    | 8          | 4          | 4                      |
  | Q    | 4          | 2          | 2                      |
  | R    | 9          | 2          | 7                      |
- 当前请求：三个进程均申请1个该类资源；
- 分配判断与安全序列：
  1. 剩余可用资源：10 -（4+2+2）= 2；
  2. 分配后检查：
     - 给Q分配1个：Q已占有3，剩余需求1；可用资源剩1；
     - 给P分配1个：P已占有5，剩余需求3；可用资源剩0；
     - 给R分配1个：R已占有3，剩余需求6；可用资源剩-1（拒绝）；
  3. 安全序列：Q→P→R（Q完成后释放3，可用资源3；P完成后释放8，可用资源8；R完成后释放9）。

#### （3）死锁检测与解除（Recover）
- 核心思想：允许死锁发生，通过检测机制发现死锁后，采取措施解除死锁。

##### ① 死锁检测
- 核心逻辑：通过“资源分配图”简化判断：
  - 资源分配图：节点（进程、资源）+ 边（进程→资源的请求边、资源→进程的分配边）；
  - 简化规则：若进程的剩余需求可被当前可用资源满足，则该进程可完成，释放所有资源（删除其所有边）；
  - 结果：若最终所有边都能删除，系统无死锁；否则，剩余边对应的进程处于死锁状态。

##### ② 死锁解除方法
- 资源剥夺法：挂起死锁进程，抢占其资源分配给其他死锁进程；需避免被挂起进程饥饿。
- 撤销进程法：强制终止部分或全部死锁进程，释放其资源；实现简单，但可能损失进程已完成的工作。
- 进程回退法：让死锁进程回退到未发生死锁的还原点；需系统记录进程历史信息，设置还原点。

### 4. 经典死锁问题：哲学家进餐问题
#### （1）问题描述
5名哲学家围坐圆桌，每两人之间有一根筷子；哲学家需同时拿起左右两根筷子才能进餐，进餐完毕后放下筷子继续思考；若筷子被占用则等待。

#### （2）解决方案
##### ① 死锁预防
- 破坏部分分配条件：要求哲学家同时拿起两根筷子（未拿到则放弃已拿的筷子）；
- 破坏环路条件：对筷子编号1-5，哲学家按编号递增顺序拿筷子（如哲学家4需先拿4号，再拿0号，避免循环）。

##### ② 死锁避免
- 引入“服务员”：哲学家拿筷子前需请示服务员，服务员判断拿筷子后是否会导致死锁，仅允许安全操作。

##### ③ 死锁检测与解除
- 设置“最长饥饿时间”：若哲学家饥饿时间超过阈值，OS介入，让其放下已拿的筷子，重新申请。

## 四、重点总结
- 资源管理功能（理解）
- 资源分配策略（理解）：先请求先服务、优先调度、针对设备特性的调度
- 死锁（掌握）：
  - 定义、举例
  - 引起死锁的原因
  - 产生死锁的必要条件
  - 死锁预防：静态资源分配法、有序资源分配方法
  - 死锁避免：银行家算法

## **真题**
系统共有 10 个资源，A ， B ，C 依次最多申请9 , 5, 6 个，已经分配 2 , 3 , 2 个 (1) 判定系统当前是否处于安全状态，如果是，给出一个安全序列 (2) 进程 A,C 先后申请 1 个资源，判定是否可以满足，给出理由。
下面按**银行家算法（单一资源类型）**来做。

已知：系统总资源数 = 10
最大需求：A=9，B=5，C=6
已分配：A=2，B=3，C=2

---

### (1) 判定当前是否安全？若安全给出安全序列

**可用资源 Available：**
$
Available = 10 - (2+3+$2$) = 3
$

**尚需资源 Need = Max - Alloc：**

* A：Need = 9 − 2 = 7
* B：Need = 5 − 3 = 2
* C：Need = 6 − 2 = 4

**安全性检查：**

* 目前 Available=3，能满足 Need≤3 的只有 **B(Need=2)**
  B 完成后释放已占有的 3 个资源：
  Available = 3 + 3 = 6

* Available=6，可满足 **C(Need=4)**
  C 完成释放 2 个资源：
  Available = 6 + 2 = 8

* Available=8，可满足 **A(Need=7)**
  A 完成释放 2 个资源：
  Available = 8 + 2 = 10

所以**系统当前处于安全状态**。

一个安全序列为：
$
\langle B,\ C,\ A\rangle
$

---

### (2) A、C 先后各申请 1 个资源，是否可满足？给理由

#### 第一步：A 申请 1 个

检查：Request(A)=1

* 1 ≤ Need(A)=7 ✅
* 1 ≤ Available=3 ✅

**试分配：**

* Available：3 → 2
* Alloc(A)：2 → 3
* Need(A)：7 → 6

再做安全性检查（此时 Available=2，Need：A6 B2 C4）：

* B Need=2 ≤ 2，可完成并释放 3 → Available=5
* C Need=4 ≤ 5，可完成并释放 2 → Available=7
* A Need=6 ≤ 7，可完成并释放 3 → Available=10

因此：**A 的申请可以满足（分配后仍安全）**。

---

#### 第二步：在满足 A 后，C 再申请 1 个

此时状态：Available=2，Need(C)=4，Alloc(C)=2。
检查：Request(C)=1

* 1 ≤ Need(C)=4 ✅
* 1 ≤ Available=2 ✅

**试分配：**

* Available：2 → 1
* Alloc(C)：2 → 3
* Need(C)：4 → 3

再做安全性检查（此时 Available=1，Need：A6 B2 C3）：

* A Need=6 > 1 ❌
* B Need=2 > 1 ❌
* C Need=3 > 1 ❌

没有任何进程能在 Available=1 下完成，因此**找不到安全序列**，系统将进入不安全状态。

结论：

* **A 的申请 1 个资源：可以满足**（仍安全）
* **C 的申请 1 个资源：不能满足**（试分配后不安全，需要等待）

# 第六章 处理机调度

## 一、处理机的多级调度
### 1. 处理机调度的功能
- 确定数据结构：构建用于管理作业和进程的核心数据结构（如JCB、PCB）。
- 制定调度策略（调度原则）：明确选择作业/进程的核心规则。
- 给出调度算法：实现调度策略的具体方法（如FCFS、短作业优先）。
- 实施处理机分派：将CPU分配给选中的进程，完成状态切换。
- 注：不同类型OS（如批处理、实时系统）采用不同的处理机分配方法。

### 2. 处理机调度的分层实现
处理机调度分为宏观和微观两层，核心围绕“内存准入”和“CPU分配”展开：
- 宏观：作业调度（高级调度）
  - 作用对象：存放在辅存的后备作业。
  - 核心任务：按策略挑选作业，分配主存等必要资源，建立对应进程，使其从后备状态转为执行状态。
- 微观：进程调度（低级调度）
  - 作用对象：已进入主存的就绪进程。
  - 核心任务：确定哪个进程何时获得CPU、使用多长时间，完成进程状态的切换。

## 二、作业调度
### 1. 作业的状态及转换
作业的生命周期包含四个核心状态，通过作业调度实现状态流转：
- 录入状态：作业被输入到辅存（如磁盘）的过程。
- 后备状态：作业已存放在磁盘，等待被调入主存（JCB已创建，进入后备队列）。
- 执行状态：作业经调度被调入主存，对应的进程在CPU上运行。
- 完成状态：作业计算完成，退出主存，系统回收资源、撤销JCB。
- 状态转换：录入 → 后备（作业提交）→ 执行（作业调度）→ 完成（作业结束）。

### 2. 作业调度的功能
- 确定数据结构：建立作业控制块（JCB），记录作业类型、状态、资源请求与分配等信息。
- 确定调度策略与算法：选择符合系统目标的作业筛选规则。
- 分配资源：为选中的作业创建进程，申请主存、外设等系统资源。
- 善后处理：作业完成后，收回其占用的全部资源，撤销JCB及相关进程。

### 3. 作业控制块（JCB）
- 定义：每个作业进入系统时由OS创建，是作业存在的唯一标志，存放作业控制和管理信息。
- 核心内容：
  - 基本信息：作业名、作业类型、优先级、控制方式。
  - 时间信息：进入系统时间、开始运行时间、估计运行时间、最迟完成时间、已运行时间。
  - 资源需求与分配：要求的内存量、外设类型及台数、文件量和输出量；已分配的内存地址、外设台号。
  - 状态信息：作业当前所处状态（后备/执行/完成）。

### 4. 作业调度算法的性能衡量
#### （1）调度算法的设计原则
- 与系统整体设计目标一致（如批处理系统追求吞吐量，实时系统追求截止时间）。
- 使系统各类资源负载均匀，避免资源闲置或过载。
- 保证作业正常执行，避免饥饿或死锁。
- 考虑专用资源的使用特性，适配设备性能。

#### （2）性能衡量指标
- 面向用户：
  - 周转时间（ti）：作业提交时间（tsi）到完成时间（tci）的间隔，ti = tci - tsi（反映作业在系统中的停留时间）。
  - 带权周转时间（wi）：周转时间与作业实际运行时间（ti_run）的比值，wi = ti / ti_run（反映作业的相对等待时间）。
  - 响应时间：作业提交到首次获得CPU响应的时间。
  - 截止时间：作业必须完成的最晚时间（实时系统关键指标）。
- 面向系统：
  - 吞吐量：单位时间内完成的作业数。
  - 资源利用率：CPU、主存等资源的使用比例。
  - 设备均衡利用：避免某类设备过度繁忙而其他设备闲置。
- 算法自身：易于实现，执行开销小。

#### （3）<font color=Crimson>常用作业调度算法</font>
| 算法名称               | 核心策略                                                                 | 特点                                                                 |
|------------------------|--------------------------------------------------------------------------|----------------------------------------------------------------------|
| 先来先服务（FCFS）     | 按作业提交的先后次序调度，选择等待最久的作业                             | 实现简单、公平；效率低，短作业可能等待长作业（“长作业拖累短作业”）     |
| 短作业优先（SJF）      | 选择估计运行时间最短的作业调入内存                                       | 系统吞吐量高；长作业可能饥饿，未考虑作业紧迫程度                       |
| 响应比高者优先（HRRN） | 响应比 = 1 + 等待时间/执行时间，每次选择响应比最高的作业                 | 折衷算法，兼顾短作业和长作业；需统计等待时间和运行时间，计算开销较大   |
| 优先数调度算法         | 按作业的优先数（综合等待时间、运行时间、缓急程度等）调度                 | 适配不同系统目标；关键是合理确定优先数（系统/用户/结合方式）           |
| 均衡调度算法           | 考虑各类资源的负载，使资源均衡利用                                       | 理想化，实现复杂，算法开销可能大于收益                                 |

#### （4）算法性能对比示例

在单道批处理系统中，有下列4个作业，分别采用先来先服务算法和最短作业优先调度算法进行调度，分析两种算法的调度性能，并填补对应表格。

##### 表1 先来先服务算法
| 作业 | 进入系统时间 | 执行时间 | 开始时间 | 完成时间 | 周转时间 | 带权周转时间 |
| --- | --- | --- | --- | --- | --- | --- |
| 4 | 9.50 | 0.20 | 9.50 | 9.70 | 0.20 | 1.00 |
| 1 | 10.00 | 2.00 | 10.00 | 12.00 | 2.00 | 1.00 |
| 2 | 10.10 | 1.00 | 12.00 | 13.00 | 2.90 | 2.90 |
| 3 | 10.25 | 0.25 | 13.00 | 13.25 | 3.00 | 12.00 |

**计算过程**
先来先服务算法按作业进入系统时间顺序执行：

1. 作业4最先进入系统（9.50），9.70完成，周转时间=9.70-9.50=0.20，带权周转时间=0.20/0.20=1.00；
2. 作业1 10.00进入系统，此时作业4已完成，无需等待，10.00开始执行，12.00完成，周转时间=12.00-10.00=2.00，带权周转时间=2.00/2.00=1.00；
3. 作业2 10.10进入系统，需等待作业1完成，12.00开始执行，13.00结束，周转时间=13.00-10.10=2.90，带权周转时间=2.90/1.00=2.90；
4. 作业3 10.25进入系统，需等待作业2完成，13.00开始执行，13.25结束，周转时间=13.25-10.25=3.00，带权周转时间=3.00/0.25=12.00。

**性能指标**

- 平均周转时间 \( t = 2.025 \)
- 平均带权周转时间 \( w = 4.225 \)

##### 表2 最短作业优先调度算法
| 作业 | 进入系统时间 | 执行时间 | 开始时间 | 完成时间 | 周转时间 | 带权周转时间 |
| --- | --- | --- | --- | --- | --- | --- |
| 4 | 9.50 | 0.20 | 9.50 | 9.70 | 0.20 | 1.00 |
| 1 | 10.00 | 2.00 | 10.00 | 12.00 | 2.00 | 1.00 |
| 3 | 10.25 | 0.25 | 12.00 | 12.25 | 2.00 | 8.00 |
| 2 | 10.10 | 1.00 | 12.25 | 13.25 | 3.15 | 3.15 |

**计算过程**
最短作业优先调度算法优先选择执行时间最短的作业：

1. 作业4最先进入系统（9.50），9.70完成，计算结果与先来先服务算法一致；
2. 作业1 10.00进入系统，10.00开始执行，12.00完成，计算结果与先来先服务算法一致；
3. 作业1完成时（12.00），作业3（10.25进入，执行时间0.25）和作业2（10.10进入，执行时间1.00）均已进入系统，优先执行作业3：12.00开始，12.25完成，周转时间=12.25-10.25=2.00，带权周转时间=2.00/0.25=8.00；
4. 作业3完成后执行作业2，12.25开始，13.25完成，周转时间=13.25-10.10=3.15，带权周转时间=3.15/1.00=3.15。

**性能指标**

- 平均周转时间 \( t = 1.8375 \)
- 平均带权周转时间 \( w = 3.2875 \)

## 三、进程调度
### 1. 调度/分派结构
处理机分配由“调度”和“分派”两个核心步骤组成：
- 调度：组织和维护就绪进程队列，确定调度算法，按算法选择待运行进程。
- 分派：当CPU空闲时，从就绪队列队首移出一个PCB，将CPU分配给该进程，使其从就绪状态转为运行状态。

### 2. 进程调度的功能
- 记录进程状态：维护所有进程的状态特征（如就绪、运行、等待）及相关信息（通过PCB）。
- 决定分配策略：根据调度目标确定策略，进而组织就绪队列（如FCFS按等待时间排队，优先数调度按优先级排队）。
- 实施CPU分配与回收：完成进程上下文切换（保存当前进程现场，恢复选中进程现场），回收终止或阻塞进程的CPU。

### 3. 进程调度方式
| 调度方式       | 核心逻辑                                                                 | 优点                     | 缺点                     |
|----------------|--------------------------------------------------------------------------|--------------------------|--------------------------|
| 非剥夺方式（非抢占式） | 进程获得CPU后，持续运行直到完成或因I/O等事件阻塞，不被其他进程打断       | 实现简单，系统开销小     | 难以满足紧急任务需求     |
| 剥夺方式（抢占式）     | 若有更高优先级进程进入就绪队列，立即暂停当前运行进程，将CPU分配给高优先级进程 | 及时响应紧急任务，灵活性高 | 增加上下文切换开销，实现复杂 |

### 4. 常用进程调度算法
#### （1）进程优先数调度算法
- 核心策略：为每个进程分配优先数，CPU空闲时选择优先数最大（或最小）的就绪进程运行。
- 优先数的确定方式：
  - 静态优先数：进程创建时确定，运行期间不变（由系统根据进程类型、资源需求确定；或由用户根据紧迫程度确定；或结合两者）。
  - 动态优先数：运行期间根据系统目标动态调整（如CPU使用超时则降低优先级，I/O完成后提高优先级，等待时间过长提高优先级）。

#### （2）循环轮转调度算法（RR）
- 核心策略：将CPU时间划分为固定大小（或可变）的时间片（q），进程获得时间片后运行，时间片用完后让出CPU，排入就绪队列队尾，循环往复。
- 关键公式：响应时间（T）= 进程数目（N）× 时间片大小（q）。
- 分类：
  - 简单循环轮转：时间片大小固定，实现简单、开销小；不灵活，进程过多时响应时间变长。
  - 可变时间片轮转：根据当前进程数动态调整时间片大小，适配系统负载。

#### （3）多级反馈算法
- 核心策略：结合多种简单算法（如优先数调度、循环轮转），设置多个就绪队列（不同队列优先级不同、时间片大小不同），进程根据运行情况在队列间迁移（如I/O频繁的进程进入高优先级队列，CPU密集型进程进入低优先级队列）。

### 5. 调度用的进程状态变迁图（示例）

<img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107033953709.png" alt="image-20251226190647628" style="zoom:67%;" />

#### （1）状态与队列结构
- 核心状态：运行状态、高优先就绪状态、低优先就绪状态、因I/O而等待状态。
- 对应队列：高优先就绪队列、低优先就绪队列、I/O等待队列。

#### （2）状态变迁规则
- 运行 → 高优先就绪：时间片用完（高优先级进程）。
- 运行 → 低优先就绪：时间片用完（低优先级进程）。
- 运行 → 因I/O而等待：进程请求I/O操作。
- 因I/O而等待 → 高优先就绪：I/O操作完成。
- 高优先就绪 → 运行：CPU空闲，高优先就绪队列非空。
- 低优先就绪 → 运行：CPU空闲，高优先就绪队列为空。

#### （3）调度算法
- 高优先就绪队列：分配时间片100ms，优先调度I/O密集型进程（I/O完成后进入该队列）。
- 低优先就绪队列：分配时间片500ms，调度CPU密集型进程（时间片用完后进入该队列）。

#### （4）调度效果
- 优先照顾I/O量大的进程（响应快），适当照顾计算量大的进程（获得较长时间片），资源利用率均衡。

## 四、重点总结
- 处理机的二级调度：作业调度（宏观，后备作业→主存）、进程调度（微观，就绪进程→CPU）。
- 作业调度：
  - 作业状态：录入、后备、执行、完成。
  - 核心数据结构：作业控制块（JCB）。
  - 核心功能：JCB管理、资源分配、善后处理。
  - 性能指标：周转时间、带权周转时间。
  - 常用算法：先来先服务、短作业优先、响应比高者优先、优先数调度。
- 进程调度：
  - 调度方式：非剥夺方式、剥夺方式。
  - 常用算法：优先数调度（静态/动态）、循环轮转调度（固定/可变时间片）。
  - 调度用状态变迁图：多状态、多队列的协同调度逻辑。
  
  
# 第七章 主存管理
## 一、主存管理概述
### 1. 主存共享方式
主存管理的核心是实现多进程对主存的高效共享，按共享区域划分方式可分为三类：
- 大小不等的区域：分区存储管理、段式存储管理；
- 大小相等的区域：页式存储管理；
- 二者结合：段页式存储管理（分段+分页）。

### 2. 程序的逻辑组织
程序地址空间分为两种结构，决定了地址访问的方式：
#### （1）一维地址结构
- 特点：程序是连续的线性地址空间，确定指令或操作数地址仅需一个信息（偏移量）；
- 地址范围：0 ~ n-1（n为程序地址空间大小）。

#### （2）二维地址结构
- 特点：程序由若干逻辑分段组成（如代码段、数据段、栈段），每个分段是连续地址区；确定地址需两个信息——分段标识+段内偏移量；
- 示例：代码分段（0 ~ 4KB-1）、数据分段（0 ~ 3KB-1）、栈段（0 ~ 2KB-1）。

## 二、主存管理的功能
### 1. 核心概念定义
- 物理地址（绝对地址/实地址）：主存单元的真实地址，物理地址集合构成主存空间；
- 逻辑地址（相对地址/虚地址）：用户程序中使用的指令或操作数地址，逻辑地址集合构成程序地址空间；
- 程序地址空间与主存空间：多个程序的逻辑地址空间独立，通过地址映射映射到同一物理主存空间。

### 2. 五大核心功能
#### （1）地址映射
- 定义：将程序地址空间的逻辑地址转换为主存物理地址的过程，又称地址重定位。
- 映射时机与类别：
  | 映射类别       | 时机                     | 实现方式                          | 特点                                                                 |
  |----------------|--------------------------|-----------------------------------|----------------------------------------------------------------------|
  | 静态地址映射   | 程序装入主存时           | 重定位装入程序（软件）            | 需一次性完成地址转换，程序运行期间地址固定，不灵活，CPU开销大         |
  | 动态地址映射   | 程序执行期间（每条指令） | 硬件地址变换机构（重定位寄存器）  | 地址转换灵活，程序可浮动，转换速度快，支持多进程共享主存             |

#### （2）主存分配
- 核心任务：为进程分配主存空间，回收空闲空间。
- 关键环节：
  1. 构造数据结构：主存资源信息块（含等待队列、空闲区队列、分配程序入口）；
  2. 制定策略：
     - 分配策略：选择请求者的原则（如优先数、FIFO）；
     - 放置策略：选择空闲区的原则（如首次适应、最佳适应）；
     - 调入策略：确定信息装入主存的时机（预先调入、请求调入）；
     - 淘汰策略：主存无空闲时，确定移出信息的原则（如LRU、FIFO）；
  3. 实施分配与回收：完成空间分配及进程结束后的资源回收。

#### （3）主存扩充（虚拟存储器）
- 核心原理：利用程序的局部性特征，将程序全部代码和数据存于辅存，仅将当前执行所需部分装入主存，执行时动态调度主存与辅存的信息。
- 虚拟存储器定义：OS与硬件配合，为用户提供的存储容量远大于实际主存的逻辑存储器。
- 核心特征：逻辑地址与物理地址分离、存储空间与虚地址空间分离、提供地址变换机构。
- 物质基础：足够容量的辅存（存放虚地址空间）、一定容量的主存（存放活跃进程信息）、地址变换机构。

#### （4）存储保护
- 定义：多用户环境中，保证各进程仅能在分配的存储区域内活动，避免相互干扰。
- 实现方法：
  1. 界地址保护：
     - 上下界防护：设置下界寄存器（主存首址）和上界寄存器（主存首址+程序大小），逻辑地址需在[下界, 上界)范围内；
     - 基地址-限长防护：设置基址寄存器（主存首址）和限长寄存器（程序大小），逻辑地址需小于限长；
  2. 存储键保护：为每个存储块和进程分配存储键，仅当二者匹配时允许访问。

## 三、<font color=Crimson>分区存储管理</font>
### 1. 动态分区分配
- 定义：进程运行过程中，根据请求大小动态建立和分配分区，进程结束后回收分区。
- 分配与回收过程：
  - 分配：按请求大小查找空闲区，空闲区与请求大小相等则直接分配，大于则分割为已分配区和剩余空闲区；
  - 回收：检查回收分区的邻接空闲区，若存在则合并为连续空闲区，否则新建空闲区并加入空闲区队列。

### 2. 核心数据结构
- 主存资源信息块（M_RIB）：含等待队列头指针、空闲区队列头指针、分配程序入口地址；
- **分区描述器（PD）**：记录分区信息（分配标志flag：0=空闲、1=已分配；大小size；勾链字next）；
- 空闲区队列：按一定规则组织空闲分区（如地址顺序、大小顺序）。

### 3. 放置策略（空闲区选择原则）
| 策略名称       | 核心逻辑                                                                 | 空闲区队列结构       | 特点                                                                 |
|----------------|--------------------------------------------------------------------------|----------------------|----------------------------------------------------------------------|
| 首次适应算法   | 选择地址最低的足够大的空闲区                                             | 按地址由低到高排序   | 利用低地址空闲区，保留高地址大空闲区，实现简单，碎片较多             |
| 最佳适应算法   | 选择与请求大小最接近的空闲区                                             | 按大小由小到大排序   | 利用小空闲区，保留大空闲区，可能产生较多小碎片                       |
| 最坏适应算法   | 选择与请求大小差距最大的空闲区                                           | 按大小由大到小排序   | 避免小碎片，但若请求频繁可能快速耗尽大空闲区，导致后续大请求无法满足 |

例题：   程序A要求18KB；程序B要求25KB；程序C要求30KB。      用首次适应算法、最佳适应算法、最坏适应算法来处理程序序列，看哪种算法合适。  

<img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107034036918.png" alt="image-20251226201842285" style="zoom: 50%;" />

### 4. 碎片问题与拼接技术

- 碎片：已分配区之间未充分利用的零散空闲区（外部碎片）。
- 拼接技术（紧凑）：移动已分配区的信息，将分散的空闲区合并为一个连续的大空闲区，解决碎片问题，但需消耗CPU时间移动数据。

### 5. 空闲区链表存储方式
- 集中存储：在OS空间开辟专用区域存储所有PD结构，优点是管理集中，缺点是占用OS空间，PD数量固定；
- 分散存储：PD分散存储在对应的分区中（空闲区的PD存于空闲区起始位置），优点是不占用额外空间，PD数量灵活，缺点是管理分散，回收时需查找PD。

## 四、<font color=Crimson>页式存储管理</font>
### 1. 基本概念
- 页面（虚页）：程序地址空间被等分为大小固定的片（如1KB、4KB）；
- 主存块（实页）：物理主存被等分为与页面大小相同的片；
- 页表：记录页面与主存块对应关系的地址变换机构，每个进程有独立页表，含页号、块号等信息；
- 核心原则：页面大小=主存块大小，实现逻辑地址与物理地址的映射。

### 2. 页式地址变换
#### （1）虚地址结构
- 组成：页号（p）+ 页内位移（w），例如16位虚地址、页面大小1KB时，页号占6位（0~15），页内位移占10位（0~1023）。

#### （2）地址变换过程（以虚地址2500为例，页面大小1KB）
1. 拆分虚地址：2500 = 2×1024 + 452，得页号p=2，页内位移w=452；
2. 查找页表：根据页表始址寄存器指示的页表地址，以p为索引找到对应的块号（如b=7）；
3. 构造物理地址：物理地址 = 块号×页面大小 + 页内位移 = 7×1024 + 452 = 7620。

#### （3）加快地址变换：联想存储器（快表）
- 快表：高速小容量半导体存储器，存放当前进程常用的页号-块号映射关系；
- 地址变换逻辑：先查快表，命中则直接获取块号；未命中则查主存页表，同时更新快表，提高地址变换速度。

### 3. 请求页式系统（虚拟页式）
#### （1）核心特征
- 程序仅需装入部分页面即可运行，执行时若所需页面不在主存，触发缺页中断，调入页面。

#### （2）扩充页表功能
- 页表项新增字段：
  - 中断位（i）：0=页面在主存，1=页面不在主存（缺页）；
  - 辅存地址：页面在辅存的存储位置；
  - 引用位（r）：0=未被访问，1=已被访问；
  - 改变位（m）：0=未被修改，1=已被修改。

#### （3）缺页处理过程
1. CPU执行指令时，拆分虚地址得到页号；
2. 查页表，若中断位=1，触发缺页中断；
3. 若主存有空闲块，直接从辅存调入页面；若无空闲块，执行页面淘汰；
4. 调整页表和存储分配表，将页面装入主存；
5. 重新启动被中断的指令。

### 4. <font color=Crimson>页面淘汰策略（置换算法）</font>
#### （1）核心概念
- 淘汰策略：选择被置换页面的规则，影响缺页中断率和系统效率；
- 缺页中断率（f′）：f/(s+f)，其中f为缺页次数，s为成功访问次数；
- 颠簸（抖动）：主存与辅存之间频繁页面置换，导致系统效率急剧下降。

#### （2）常用置换算法
| 算法名称       | 核心逻辑                                                                 | 实现方式                          | 特点                                                                 |
|----------------|--------------------------------------------------------------------------|-----------------------------------|----------------------------------------------------------------------|
| 最佳算法（OPT） | 淘汰以后不再使用或最长时间后才使用的页面                                 | 需预知页面访问序列                | 理论最优，无法实际实现                                               |
| 先进先出（FIFO） | 淘汰最早进入主存的页面                                                   | 建立页面进入次序表，用替换指针指向最老页面 | 实现简单，可能出现“Belady异常”（分配块数增加，缺页率反而上升）         |
| 最久未使用（LRU） | 淘汰最长时间未被使用的页面                                               | 硬件计数器或软件页号栈             | 接近最优，实现复杂（硬件支持或软件开销大）                           |
| LRU近似算法    | 遍历页面引用位，淘汰引用位为0且最早遇到的页面                             | 替换指针循环扫描，重置引用位       | 实现简单，性能接近LRU，开销小                                       |

#### （3）页号栈方法

以LRU为例

<img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107034042803.png" alt="image-20251227020212318" style="zoom:50%;" />

## 五、段式及段页式存储管理

### 1. 段式存储管理
#### （1）基本概念
- 段：程序的逻辑划分（如代码段、数据段、栈段），段长可变，用户可见；
- 段地址空间：二维地址结构，由段号（s）和段内位移（w）组成；
- 段表：每个进程有独立段表，记录段号、段长（L）、段基址（B），实现段的地址映射和存储保护。

#### （2）段式地址变换过程
1. 取出逻辑地址（s，w）；
2. 用段号s检索段表，获取段长L和段基址B；
3. 检查段内位移w：若w≥L，触发越界中断；
4. 构造物理地址：物理地址 = B + w。

#### （3）页式与段式系统的区别
| 对比维度       | 页式系统                          | 段式系统                          |
|----------------|-----------------------------------|-----------------------------------|
| 地址空间       | 一维地址空间（页号+页内位移）     | 二维地址空间（段号+段内位移）     |
| 划分依据       | 物理划分（页面大小固定）          | 逻辑划分（段长可变）              |
| 用户可见性     | 不可见（OS管理）                  | 可见（用户定义段）                |
| 地址溢出处理   | 页内位移溢出自动进位到页号       | 段内位移溢出触发越界中断          |
| 主要优点       | 无外部碎片，主存利用率高          | 逻辑结构清晰，支持段共享和保护    |

### 2. 段页式存储管理
#### （1）核心思想
结合分段和分页的优点：先将程序按逻辑划分为段，再将每个段等分为固定大小的页面，主存按块分配，实现“段式管理+页式管理”的结合。

#### （2）地址结构
- 组成：段号（s）+ 页号（p）+ 页内位移（w）。

#### （3）地址变换过程
1. 用段号s检索段表，获取该段的页表始址；
2. 用页号p检索该段的页表，获取对应的主存块号；
3. 用块号和页内位移w构造物理地址；
4. 全程需两次查表（段表→页表），可通过快表优化速度。

#### （4）段表、页表与主存的关系
- 段表：每个进程1个，记录各段的页表长度和页表始址；
- 页表：每个段1个，记录该段页面与主存块的对应关系；
- 主存：按块分配，存放各段的页面数据。

## 六、重点总结
- 基本概念（理解）：
  - 逻辑地址/物理地址、程序地址空间/主存空间；
  - 地址映射（静态/动态）、虚拟存储器、存储保护（界地址保护）；
  
- 分区存储管理（掌握）：
  - 动态分区的分配与回收、放置策略（首次/最佳/最坏适应）；
  - 碎片问题与拼接技术；
  
- 页式存储管理（掌握）：
  - 页面/主存块、页表、地址变换过程；
  - 请求页式系统、缺页处理、页面淘汰算法（FIFO/LRU）；
  
- 段式及段页式存储管理（理解）：
  - 段式系统的二维地址结构与地址变换；
  - 段页式系统的结合逻辑与地址变换流程。
  
  
## 真题

**某系统采用动态分区分配方式管理内存，空闲分区按地址从低到高排列。初始空闲区如下表所示（单位：KB）：**

| 分区号 | 大小 |
| :-- | :- |
| 1   | 15 |
| 2   | 5  |
| 3   | 25 |
| 4   | 56 |

**现有作业依次请求分配：5KB、15KB、35KB。分配完成后，空闲区列表仅剩两个分区，大小分别为 25KB 和 21KB。**

**(1) 判定分配原则为（首次适应/最佳适应/最坏适应）。原因是什么？**
**(2) 画出分配后的空闲区队列图。**

---

### 题目解析与答案

#### (1) 判定分配原则

**答案：最佳适应算法 (Best Fit)**

**原因分析（推导过程）：**

我们需要将三种算法代入验证，看哪一种能得出题目描述的最终状态（剩 25KB 和 21KB）。

1. **假设采用 首次适应算法 (First Fit)：**

   * *原则：从低地址查找，找到第一个能放下作业的分区。*
   * 申请 5KB：查分区1(15KB) -> 够放。分区1剩 10KB。

     * 当前状态：10, 5, 25, 56
   * 申请 15KB：查分区1(10KB, 不够), 查分区2(5KB, 不够), 查分区3(25KB) -> 够放。分区3剩 10KB。

     * 当前状态：10, 5, 10, 56
   * 申请 35KB：前三个都不够，查分区4(56KB) -> 够放。分区4剩 21KB。

     * 最终结果：剩 10KB, 5KB, 10KB, 21KB四个碎片。
   * **结果：与题目“剩两个分区”不符。**

2. **假设采用 最坏适应算法 (Worst Fit)：**

   * *原则：总是挑选最大的分区进行分配。*
   * 申请 5KB：最大是分区4(56KB)。分区4剩 51KB。

     * 当前状态：15, 5, 25, 51
   * 申请 15KB：最大是分区4(51KB)。分区4剩 36KB。

     * 当前状态：15, 5, 25, 36
   * 申请 35KB：最大是分区4(36KB)。分区4剩 1KB。

     * 最终结果：剩 15, 5, 25, 1。
   * **结果：与题目不符。**

3. **假设采用 最佳适应算法 (Best Fit)：**

   * *原则：挑选能满足作业要求的、且大小最接近（最小）的空闲分区。*
   * **申请 5KB**：遍历 [15, 5, 25, 56]。**5KB** 分区刚好满足且最小。

     * 操作：占用分区2。
     * 当前空闲链：15, 25, 56
   * **申请 15KB**：遍历 [15, 25, 56]。**15KB** 分区刚好满足且最小。

     * 操作：占用分区1。
     * 当前空闲链：25, 56
   * **申请 35KB**：遍历 [25, 56]。25不够，只能选 **56KB**。

     * 操作：占用分区4，剩余 56 - 35 = 21KB。
     * 当前空闲链：25, 21
   * **结果：剩余 25KB 和 21KB。**
   * **结论：完全符合题目描述。**

---

#### (2) 画出分配后的空闲区队列图

根据上述分析，原来的第3个分区（25KB）未被动过，原来的第4个分区（56KB）被切分后剩下了高地址部分的21KB。

**空闲区队列图如下：**

```text
Head ──> [ 分区3: 25KB ] ──> [ 分区4剩余: 21KB ] ──> NULL
```

或者用更详细的示意图表示（假设地址从左到右递增）：

```text
+-------------------+       +-------------------+
|   空闲区 (原分区3) |       |   空闲区 (原分区4) |
|      Size: 25KB   | ----> |      Size: 21KB   | ----> NULL
+-------------------+       +-------------------+
```

注：原分区1和分区2已被全部分配，因此不再出现在空闲



真题2：

某采用页式存储的操作系统，其虚拟地址和物理地址均为20位，页表项和页目录项均为16位对齐。

(1) 假设单页2KB，请问**最少**需要使用几级页表？每级对应的逻辑地址是几位。如果要进行逻辑地址

到物理地址的转换，需要几次访存？

(2) 假设单页1KB，请问**最少**需要使用几级页表？每级对应的逻辑地址是几位。如果要进行逻辑地址

到物理地址的转换，需要几次访存？

### 题目解析与答案

这也是一道非常经典的操作系统内存管理题目，主要考察**多级页表**的设计计算。

解答这类问题的核心逻辑在于：**单个页面（页表）能容纳多少个页表项（PTE），决定了每一级页表所能映射的逻辑地址位数。**

已知基础条件如下：

- **虚拟/物理地址位数**：20位
- **页表项大小**：16位对齐（即 **2字节**, $2^1$ Bytes）

------

#### (1) 假设单页 2KB

**1. 计算页内偏移（Offset）**

- 页面大小为 2KB = $2 \times 1024$ B = $2^{11}$ Bytes。
- 所以，**页内偏移量占 11 位**。

**2. 计算虚页号（VPN）总位数**

- 总地址 20 位 - 页内偏移 11 位 = **9 位**。
- 这意味着系统需要映射 $2^9$ 个页面。

**3. 计算单个页面能容纳的页表项数量**

- 单页容量 / 页表项大小 = $2^{11} \text{B} / 2 \text{B} = 2^{10}$ 个页表项。
- 即：一级页表**最多**可以映射 10 位逻辑地址。

**4. 判定级数与位宽**

- 我们需要映射的虚页号只有 **9 位**。
- 因为 $9 < 10$（需要的位数 < 单级页表能容纳的位数），所以**只需要一级页表**即可容纳所有映射关系。

**答案：**

- **最少级数**：**1级**。
- **对应的逻辑地址位数**：该级对应 **9位**（即虚页号全长）。
- **访存次数**：**2次**。
  - 第1次：访问内存中的页表，获取物理页框号。
  - 第2次：访问物理地址对应的目标数据。

------

#### (2) 假设单页 1KB

**1. 计算页内偏移（Offset）**

- 页面大小为 1KB = $1024$ B = $2^{10}$ Bytes。
- 所以，**页内偏移量占 10 位**。

**2. 计算虚页号（VPN）总位数**

- 总地址 20 位 - 页内偏移 10 位 = **10 位**。
- 这意味着系统需要映射 $2^{10}$ 个页面。

**3. 计算单个页面能容纳的页表项数量**

- 单页容量 / 页表项大小 = $2^{10} \text{B} / 2 \text{B} = 2^9$ 个页表项。
- 即：每一级页表**最多**只能映射 **9 位**逻辑地址。

**4. 判定级数与位宽**

- 我们需要映射的虚页号有 **10 位**。
- 由于单级只能处理 9 位 ($10 > 9$)，一张页表装不下所有的映射项，因此必须拆分为**两级页表**。
- **拆分方式**：
  - 低级页表（二级）通常填满或尽可能大：最多 9 位。
  - 顶级页表（一级/页目录）：剩余的 $10 - 9 = 1$ 位。

**答案：**

- **最少级数**：**2级**。
- **对应的逻辑地址位数**：
  - 第一级（页目录）：**1位**。
  - 第二级（页表）：**9位**。
- **访存次数**：**3次**。
  - 第1次：访问内存中的页目录（一级），获得二级页表地址。
  - 第2次：访问内存中的二级页表，获得物理页框号。
  - 第3次：访问物理地址对应的目标数据。

------

#### 总结对照表

| 场景    | 页面大小       | 页内偏移 | 虚页号(VPN)总长 | 单页最大索引能力 | 所需级数 | 地址划分    | 总访存次数 |
| ------- | -------------- | -------- | --------------- | ---------------- | -------- | ----------- | ---------- |
| **(1)** | 2KB ($2^{11}$) | 11位     | 9位             | 10位 ($2^{10}$)  | **1级**  | VPN(9)      | **2次**    |
| **(2)** | 1KB ($2^{10}$) | 10位     | 10位            | 9位 ($2^9$)      | **2级**  | P1(1)+P2(9) | **3次**    |



# 第八章 设备管理 
## 一、设备管理概述
### 1. 设备分类
根据功能和数据传输方式，计算机设备可分为三类：
- 存储设备（块设备）：以块为单位传输信息，用于存储数据，如磁盘、磁鼓；
- 输入输出设备（字符设备）：以字符为单位传输信息，实现人机交互或数据输入输出，如键盘、显示器、打印机；
- 通信设备：负责计算机之间的信息传输，如调制解调器、网卡。

### 2. 设备管理的目标
- 提高设备利用率：合理分配设备，提升设备与CPU、设备与设备之间的并行性；
- 方便用户使用：提供统一、设备无关的操作界面，用户无需关注物理设备细节。

### 3. 设备管理的核心功能
- 状态跟踪：动态记录各类设备的当前状态（空闲、忙碌、故障等）；
- 设备分配与回收：
  - 静态分配：应用程序级分配，程序进入系统时分配设备，退出时回收；
  - 动态分配：进程级分配，进程提出申请时分配设备，使用完毕后立即回收；
- 设备控制：实现设备驱动和中断处理，完成实际的I/O操作。

### 4. 设备独立性
#### （1）核心概念
- 设备独立性：用户程序中使用逻辑设备名，与实际物理设备无关；
- 逻辑设备名：用户指定的临时设备名，可更改；
- 物理设备名：系统规定的永久设备名，不可更改。

#### （2）两种类型的设备独立性
- 程序独立于某类设备的具体物理设备：系统可动态分配某类设备中的任意一台，程序均能正常执行；
- 程序独立于设备类型：输入输出信息可切换不同类型设备，程序仅需少量修改。

#### （3）实现方式
- 高级语言：通过系统调用指定逻辑设备名（如 `fd = open("/dev/lp", mode)`）；
- 批处理系统：用联接说明语句定义（如 `OUTPUT1 = LPT`）；
- 交互系统：用指派命令定义（如 `ASSIGN 物理设备名 逻辑设备名`）。

#### （4）优点
- 方便用户操作，无需记忆物理设备名；
- 提高设备利用率，系统可灵活分配空闲设备；
- 增强系统可扩展性和适应性，新增设备无需修改用户程序。

### 5. 设备控制块（DCB）
#### （1）定义
系统为每台设备配置的数据结构，记录设备的硬件特性、连接状态和使用情况，是设备存在的标志。

#### （2）核心内容
- 设备名：设备的物理名（系统标准名称）；
- 设备属性：描述设备现行状态的属性集合；
- 命令转换表指针：指向设备特定的I/O例程地址（不支持功能的设备填“-1”）；
- I/O总线地址：设备在I/O总线上的物理地址；
- 设备状态：空闲、忙碌、故障等；
- 当前用户进程指针：指向正在使用该设备的进程；
- I/O请求队列指针：指向等待该设备的I/O请求队列。

## 二、缓冲技术
### 1. 缓冲的概念与作用
#### （1）核心定义
- 缓冲：缓冲是两种不同速度的设备之间传输信息时平滑传输过程的常用手段。
- ① 缓冲器：用来暂时存放数据的一种存储装置，它容量较小，存取速度快。
- ② 软件缓冲：在I/O操作期间用来临时存放I/O数据的一块存储区域

#### （2）引入缓冲的原因
- 解决设备速度差异：平衡数据流生产者（如CPU）与消费者（如打印机）的速度不匹配；
- 协调数据传输大小：处理不同设备间传输数据单位不一致的问题（如网络消息的分段与重组）；
- 保证拷贝语义：操作系统通过内核缓冲复制应用程序数据，确保写操作的正确性（如 `write` 系统调用的数据版本一致性）。

### 2. 缓冲的I/O操作流程
#### （1）读操作（从输入设备读取数据）
1. 进程请求读操作，系统分配一个空缓冲区；
2. 输入设备将物理记录写入缓冲区；
3. 系统从缓冲区提取逻辑记录，发送到进程存储区；
4. 若缓冲区为空，进程需等待，直至设备重新填满缓冲区。
- 关键：缓冲区写操作（设备→缓冲区）与读操作（缓冲区→进程）需同步。

#### （2）写操作（向输出设备输出数据）
1. 进程请求写操作，系统分配一个空缓冲区；
2. 进程将逻辑记录写入缓冲区；
3. 缓冲区写满后，系统将其作为物理记录写入输出设备，缓冲区复位为空；
4. 若缓冲区未腾空，进程需等待，直至设备完成输出。
- 关键：缓冲区写操作（进程→缓冲区）与输出操作（缓冲区→设备）需同步。

### 3. 常用缓冲技术
#### （1）双缓冲
- 核心逻辑：为输入或输出分配两个缓冲区（buf1、buf2），实现设备与进程的并行操作；

- 读操作：设备向buf1写数据时，进程可从buf2读数据，交替进行，减少等待时间；

- 写操作：进程向buf1写数据时，设备可从buf2读数据，并行执行；

- 双向使用：两个缓冲区可分别用于输入和输出，进一步提升并行性。

  <img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107033959543.png" alt="image-20251229213052181" style="zoom:50%;" />

#### （2）其他缓冲技术
- 环形缓冲：多个缓冲区组成环形队列，循环使用，适配高吞吐量的I/O场景；
- 缓冲池：系统维护一组公共缓冲区，供所有进程共享，提高缓冲区利用率。

### 4. UNIX系统的缓冲区管理
#### （1）管理目标与思路
- 目标：加快系统响应速度，增强吞吐量，减少磁盘I/O次数；
- 思路：预先缓存（读数据时优先从高速缓冲读取）、延迟发送（写数据时先写入高速缓冲，后续批量写入磁盘）。

#### （2）核心数据结构
- 缓冲区组成：缓存数组（存储磁盘数据）+ 缓存首部（描述缓冲区特性）；
- 缓存首部字段：设备号（dev）、块号（blkno）、状态（flag）、数据指针、传送字节数、I/O出错信息、设备队列指针（b_forw/b_back）、空闲队列指针（av_forw/av_back）；
- 队列结构：
  - 设备缓冲区队列（b链）：同一设备的所有缓冲区组成的队列；
  - 空闲缓冲区队列（av链）：可供分配的缓冲区组成的队列。

#### （3）管理算法
1. 缓冲区分配：分配时置BUSY标志，从av链移除，加入对应设备的b链；
2. 缓冲区释放：I/O完成后重置BUSY标志，保留在b链，同时加入av链尾部；
3. 缓存命中：进程请求的数据已在缓冲区时，从av链移除该缓冲区，使用后送回av链尾部；
4. 空闲缓冲区调度：分配时取av链首元素，释放时插入av链尾部，实现LRU淘汰算法；
5. 延迟写处理：带DELWR标志的缓冲区移至av链头时，立即执行写磁盘操作，避免数据丢失。

## 三、设备分配
### 1. 设备分配技术分类
#### （1）独享分配（独占分配）
- 适用设备：独享设备（临界资源，如打印机、输入机），需人工干预或耗时I/O操作；
- 分配逻辑：作业执行前分配设备，作业结束后回收，确保设备独占使用，避免冲突；
- 特点：实现简单，设备利用率低。

#### （2）共享分配
- 适用设备：共享设备（可随机访问的旋转设备，如磁盘）；
- 分配逻辑：进程提出申请时分配设备，使用完毕后立即回收，允许多进程交替使用；
- 特点：设备利用率高，需解决并发访问的同步问题。

#### （3）虚拟分配（虚拟设备技术）
- 虚拟技术：所谓虚拟技术，是在一类物理设备上模拟另一类物理设备的技术，是将独占设备转化为共享设备的技术。
- 虚拟设备：通常把用来代替独占型设备的那部分外存空间 (包括有关的控制表格)称为虚拟设备。
- 虚拟分配：当进程需要与独占型设备交换信息时，系统将分配磁盘空间，并建立相应的数据结构，这种分配方法称为设备的虚拟分配。

### 2. SPOOLING系统（假脱机系统）
#### （1）设计思想
- 预输入：应用程序需要数据前，OS将数据从独占设备预先输入到辅存输入井；
- 缓输出：应用程序的输出数据先写入辅存输出井，待程序执行完毕或需要数据时，由操作系统将数据输出。

#### （2）定义与组成
- 定义：利用通道和中断技术，在主机控制之下，由通道完成输入输出工作。系统提供一个软件系统 (包括预输入程序、缓输出程序、井管理程序、预输入表、缓输出表)。它提供输入收存和输出发送的功能，使外部设备可以并行操作。这一软件系统称为SPOOLING系统。
- 组成：
  - 硬件基础：通道装置、中断系统；
  - 辅存空间：输入井（存放预输入数据）、输出井（存放缓输出数据）；
  - 数据结构：预输入表（记录输入数据的设备、位置）、缓输出表（记录输出数据的位置、目标设备）；
  - 软件程序：预输入程序（控制设备→输入井）、缓输出程序（控制输出井→设备）、井管理程序（控制进程与输入井/输出井的交互）。

#### （3）优点
- 提供虚拟设备，将独占设备转化为共享设备；
- 实现外围设备联机并行操作，多个进程可同时使用虚拟设备；
- 加快作业处理速度，减少进程等待设备的时间。

## 四、I/O控制
### 1. I/O控制方式
根据I/O控制器的智能化程度，分为四类控制方式：
- 循环测试I/O方式（程序查询方式）：CPU不断查询设备状态，忙则等待，闲则执行I/O，CPU利用率低；
- I/O中断方式：设备完成I/O后触发中断，CPU暂停当前任务处理中断，效率高于循环测试；
- DMA方式（直接内存访问）：设备通过DMA控制器直接与内存传输数据，无需CPU干预，解放CPU；
- 通道方式：专用的I/O处理单元，独立执行I/O指令，控制多台设备并行操作，CPU负担最轻。

### 2. I/O子系统
#### （1）结构组成
- 软件层：内核I/O子系统（提供标准接口）、设备驱动程序（封装设备差异，适配各类硬件）；
- 硬件层：设备控制器（连接CPU与物理设备）、物理设备（执行实际I/O操作）；
- 核心特点：应用层通过标准I/O接口访问设备，设备驱动程序隐藏硬件差异，实现I/O子系统与硬件的分离。

#### （2）核心功能
- 解释I/O系统调用：将用户的设备操作请求转换为内核可识别的命令；
- 设备驱动：通过设备驱动程序控制设备控制器，执行具体的I/O操作；
- 中断处理：响应设备中断，处理I/O完成、错误等事件。

### 3. I/O控制流程
#### （1）系统调用形式
用户进程通过系统调用请求I/O操作：`doio(ldev, mode, amount, addr)`，其中：
- ldev：逻辑设备名；
- mode：操作模式（读/写）；
- amount：传输数据量；
- addr：数据传输地址（进程内存地址）。

#### （2）I/O接口程序流程（内核层）
1. 逻辑设备→物理设备转换：通过逻辑设备描述器找到对应的物理设备；
2. 合法性检查：验证操作模式与设备特性是否一致（如只读设备不允许写操作）；
3. 构造I/O请求块（IORB）：包含设备名、操作类型、数据量、地址等信息；
4. 提交请求：将IORB加入设备的请求队列，唤醒等待的设备处理进程。

#### （3）设备处理进程流程
1. 循环检查设备请求队列，若为空则睡眠；
2. 取出队列首IORB，提取请求信息，启动I/O操作；
3. 睡眠等待I/O完成（由中断处理程序唤醒）；
4. I/O完成后，检查是否出错，将数据传输到目标地址；
5. 唤醒请求I/O的用户进程，删除IORB，继续处理下一个请求。

#### （4）同步关系
- 控制关系：用户进程→I/O接口程序→设备处理进程→设备控制器→物理设备；
- 同步关系：设备处理进程等待I/O完成（中断触发），用户进程等待I/O处理进程完成，中断处理程序唤醒设备处理进程。

## 五、重点总结
- 设备管理基础（理解）：
  - 设备分类（块设备/字符设备/通信设备）、设备独立性（逻辑/物理设备名）；
  - 设备控制块（DCB）的功能与核心字段；
- 缓冲技术（掌握）：
  - 缓冲的作用、双缓冲的并行逻辑；
  - UNIX缓冲管理的LRU淘汰算法；
- 设备分配（理解）：
  - 三类分配技术（独享/共享/虚拟分配）的适用场景；
  - SPOOLING系统的组成、设计思想与优点；
- I/O控制（理解）：
  - 四种I/O控制方式的特点；
  - I/O子系统的结构、I/O请求的处理流程及各组件的同步关系。

## 真题
输入设备和系统共享单缓冲区，输入设备将数据块写入缓冲区需要 100ms，系统从缓冲区读数据
块需要 5ms，系统读取后分析数据需要 90ms
(1) 系统完成两个数据块的分析，需要最短多长时间，给出理由
(2) 使用 PV 信号灯描述该过程的并发与同步

---

### (1) 系统完成两个数据块的分析，需要最短多长时间？

**答案：300ms**

#### 详细理由与时序分析

在单缓冲区模式下，**输入设备往缓冲区写数据** 和 **系统从缓冲区读数据** 是互斥的（不能同时发生），但 **输入设备写数据** 和 **系统分析数据** 可以并行进行（前提是缓冲区已空）。

让我们按时间轴推演两个数据块的处理过程：

1. **第一个数据块 (Block 1):**

   * **0ms - 100ms ($T_{in}$):** 输入设备将 Block 1 写入缓冲区。
   * **100ms - 105ms ($T_{move}$):** 系统将 Block 1 移出缓冲区。此时缓冲区变空。
   * **105ms - 195ms ($T_{process}$):** 系统开始分析 Block 1。

2. **第二个数据块 (Block 2) 的并行处理:**

   * **105ms:** 一旦系统在 105ms 完成了数据移动（$T_{move}$），缓冲区变为空，输入设备**立即**开始写入 Block 2。
   * **105ms - 205ms ($T_{in}$):** 输入设备写入 Block 2。
   * *注意：此时系统正在并行分析 Block 1（105ms-195ms）。系统在 195ms 完成分析后，处于空闲等待状态，直到 205ms 输入设备完成写入。*

3. **第二个数据块的后续处理:**

   * **205ms:** Block 2 写入完成。
   * **205ms - 210ms ($T_{move}$):** 系统将 Block 2 移出缓冲区。
   * **210ms - 300ms ($T_{process}$):** 系统分析 Block 2。

**总耗时图解：**

| 时间段 (ms)      | 输入设备 (Input Device) | 缓冲区操作          | 系统/CPU (System)     |
| :------------ | :------------------ | :------------- | :------------------ |
| **0 - 100**   | **写入 Block 1**      | 满              | 闲                   |
| **100 - 105** | 闲                   | **移动 Block 1** | **读取 Block 1**      |
| **105 - 195** | **写入 Block 2** (并行) |                | **分析 Block 1** (并行) |
| **195 - 205** | **写入 Block 2** (继续) | 满              | 闲 (等待 I/O)          |
| **205 - 210** | 闲                   | **移动 Block 2** | **读取 Block 2**      |
| **210 - 300** | 闲                   | 空              | **分析 Block 2**      |

**计算公式：**
$$Total = T_{in} + T_{move} + \max(T_{process}, T_{in}) + T_{move} + T_{process}$$
$$Total = 100 + 5 + \max(90, 100) + 5 + 90$$
$$Total = 105 + 100 + 95 = 300\text{ms}$$

---

### (2) 使用 PV 信号灯描述该过程的并发与同步

这是一个典型的 **生产者-消费者 (Producer-Consumer)** 问题，缓冲区大小为 1。

#### 1. 信号量定义 (Semaphores)

我们需要两个信号量来控制缓冲区的状态：

* `empty`: 表示缓冲区是否为空（能否写入）。

  * **初值 = 1**（开始时缓冲区是空的）。
* `full`: 表示缓冲区是否有数据（能否读取）。

  * **初值 = 0**（开始时缓冲区没有数据）。

*(注：由于是单缓冲区，且只有一个生产者和一个消费者，`empty` 和 `full` 已经隐含了互斥锁的功能，因此通常不需要额外的 `mutex` 信号量)*

#### 2. 进程描述

```c
// 信号量初始化
semaphore empty = 1; 
semaphore full = 0;

// 输入设备进程 (生产者)
Input_Device() {
    while (TRUE) {
        // 1. 准备数据 (耗时: 0, 假设数据源源不断)
        
        P(empty);  // 申请缓冲区空间。若满，则等待。
        
        // 2. 将数据块写入缓冲区 (临界区)
        // 耗时: 100ms
        Write_To_Buffer(); 
        
        V(full);   // 释放“满”信号，通知系统有数据可读。
    }
}

// 系统进程 (消费者)
System_Process() {
    while (TRUE) {
        P(full);   // 等待缓冲区有数据。
        
        // 3. 从缓冲区读取数据 (临界区)
        // 耗时: 5ms
        Read_From_Buffer(); 
        
        V(empty);  // 释放“空”信号，通知输入设备可以写新数据了。
        
        // 4. 分析数据 (非临界区，可与输入设备并行)
        // 耗时: 90ms
        Analyze_Data(); 
    }
}
```

#### 3. 执行逻辑解析

1. **同步机制**：`P(full)` 保证了系统不会在缓冲区为空时读取；`P`P(empty)` 保证了输入设备不会在缓冲区已满（系统还没读走数据）时覆盖写入。
2. **并发实现**：当系统执行 `V(empty)` 后，输入设备就可以通过 `P(empty`P(empty)` 开始写下一个数据块（耗时 100ms），与此同时，系统正在执行 `Analyze_Data()`Analyze_Data()`（耗时 90ms）。这就是第一问中并行处理的实现原理。

# 第九章 文件系统
## 一、文件系统的基本概念
### 1. 文件的定义与分类
#### （1）核心定义
文件是逻辑上具有完整意义的信息集合，有唯一标识符（文件名），基本组成单位为信息项或记录。
- 文件名：以字母开头的字母数字串，含符号名（用户使用）和内部标识符（系统管理）；
- 文件扩展：表示文件使用特征（如 `.c`、`.obj`、`.lib`）；
- 文件属性：描述文件类别、保护级等信息的属性字。

#### （2）文件分类
| 分类维度       | 具体类型                                                                 |
|----------------|--------------------------------------------------------------------------|
| 性质与用途     | 系统文件、程序库文件、用户文件                                           |
| 保护级别       | 不保护文件、执行文件、只读文件、读写文件                                 |
| 流向           | 输入文件、输出文件、输入输出文件                                         |

### 2. 文件系统的定义与功能
#### （1）核心定义
文件系统是操作系统中负责管理和存取文件信息的软件机构，由管理数据结构（目录表、文件控制块、存储分配表）、管理程序和一组操作组成。

#### （2）核心功能
- 用户视角：实现“按名存取”，提供简单易用的文件操作接口；
- 系统视角：管理辅存空间（文件块、空闲块分配）、管理文件集合（结构、存取、共享）、文件保护（可靠性与安全性）。

#### （3）特点
- 使用简单：通过文件名和文件操作命令交互；
- 安全可靠：支持全量备份、增量备份、动态备份、远程备份等防护措施；
- 共享与保密：通过身份验证、存取权限验证实现。

### 3. 文件的两种结构
#### （1）逻辑结构（逻辑文件）
- 定义：从用户角度看到的文件结构，即用户对信息进行逻辑组织形成的文件结构。
- 目的：为用户提供清晰、易用的文件形式，方便存储、检索和加工信息。

#### （2）物理结构（物理文件）
- 定义：信息在物理存储器上的存储方式，是数据的物理表示和组织；
- 目的：选择性能良好、设备利用率高的存储形式，适配物理设备的I/O特性。

#### （3）逻辑记录与物理记录
- 逻辑记录：按信息逻辑含义划分的独立单位，是文件存取的基本单位；
- 物理记录：存储介质上的连续信息区域（块），是物理I/O的基本单位；
- 关系：逻辑记录需映射到物理记录存储，二者大小可不同。

## 二、文件的逻辑结构与存取方法
### 1. 逻辑结构分类
#### （1）流式文件
- 定义：无结构的有序字符集合，不划分记录；
- 存取方式：按字符个数或特殊字符为界进行存取。

#### （2）记录式文件
- 定义：有结构的文件，由连续顺序的记录组成；
- 分类：
  - 定长记录：所有记录长度相同，存储和检索效率高；
  - 变长记录：记录长度不同，需额外存储记录长度信息。

### 2. 文件存取方法
#### （1）顺序存取
- 逻辑：后一次存取基于前一次位置，无需指定具体位置；
- 适用场景：流式文件、顺序存储的记录式文件（如磁带文件）。

#### （2）随机存取
- 逻辑：用户以任意次序请求记录，需指定起始存取位置（如记录号）；
- 适用场景：索引文件、随机存储设备（如磁盘文件）。

## 三、文件的物理结构
文件物理结构决定文件在辅存的存储方式，核心需平衡存取速度、空间利用率和扩展性，常用结构如下：

### 1. 连续文件
#### （1）定义
文件的所有物理块连续分配在磁盘的连续区域，目录项记录文件首块号和块数。

#### （2）特点
- 优点：结构简单、实现容易，顺序存取速度快；
- 缺点：文件长度固定，动态增减困难，易产生外部碎片，存储空间利用率低。

#### （3）示例
文件A含3个记录（与物理块大小均为512B），首块号100，则存储在块100、101、102。

### 2. 串联文件（链接文件）
#### （1）定义
文件的物理块分散存储，每个物理块的末尾存放下一块的物理地址，最后一块的链接字为结束标记（），目录项记录首块号。

#### （2）变形：文件分配表（FAT）
- 核心逻辑：将所有块的链接指针集中存储在FAT表中，每个块对应一个表目，记录下一块地址；
- 优点：简化链接管理，减少块内链接字开销，提高存取效率。

#### （3）特点
- 优点：充分利用辅存空间，无碎片，文件长度灵活，易于增减；
- 缺点：随机存取效率低（需遍历链表），链接字出错可能导致文件损坏。

### 3. 索引文件
#### （1）定义
系统为每个文件建立索引表，记录逻辑块号与物理块号的映射关系，文件由索引表和数据块组成，目录项记录索引表地址。

#### （2）多级索引（解决大文件存储）
- 直接索引：目录项直接记录物理块号，适用于小型文件；
- 一级间接索引：目录项记录一级索引表块号，索引表块记录数据块号，适用于中型文件；
- 二级间接索引：目录项记录二级索引表块号，二级索引表块记录一级索引表块号，适用于大型文件。

#### （3）特点
- 优点：支持随机存取和动态增减，无碎片；
- 缺点：索引表占用额外空间，存取需多一次索引表查询，有时间开销。

### 4. 物理结构对比
| 结构类型       | 优点                                  | 缺点                                  | 适用场景                          |
|----------------|---------------------------------------|---------------------------------------|-----------------------------------|
| 连续文件       | 顺序存取快，实现简单                  | 动态扩展难，有碎片                  | 短文件、顺序存取文件（如磁带）    |
| 串联文件       | 空间利用率高，扩展灵活                | 随机存取慢，可靠性差                | 流式文件、顺序存取文件（如日志）  |
| 索引文件       | 随机存取快，支持大文件                | 索引表开销，存取延迟                | 随机存取文件、大文件（如数据库）  |

## 四、文件目录
文件目录是管理文件的核心数据结构，实现“按名存取”，记录文件的文件名、物理地址及其他属性。

### 1. 目录项的核心内容
- 文件名：文件的符号名；
- 逻辑结构：记录文件是否为定长记录、记录长度等；
- 物理结构：
  - 连续文件：首块号、块数；
  - 串联文件：首块号；
  - 索引文件：索引表地址；
- 存取控制信息：文件主及其他用户的存取权限；
- 管理信息：文件建立时间、最后存取时间、保留时间；
- 文件类型：数据文件、目录文件、设备文件等。

### 2. 目录结构分类
#### （1）一级文件目录
- 定义：系统建立一张全局目录表，记录所有文件的目录项；
- 优点：实现简单，按名存取；
- 缺点：目录检索效率低，不支持重名（多用户环境下命名冲突）。

#### （2）树型文件目录
- 定义：目录呈树形层次结构，根目录为顶层，非叶节点为目录文件，叶节点为数据文件；
- 核心概念：
  - 文件路径名：根目录到文件的通路字符串，如 `/b/f/j`；
  - 当前目录（值班目录）：用户当前工作目录，文件访问可基于当前目录使用相对路径；
- 优点：解决重名问题（不同路径下文件名可相同），目录检索效率高，支持文件分类管理。

## 五、UNIX文件系统的主要结构及实现技术
### 1. UNIX文件系统的特点
- 树型目录结构，支持可安装/拆卸的文件系统；
- 文件是无结构的字符流式文件；
- 外部设备视为特别文件（块设备文件、字符设备文件）。

### 2. UNIX文件类型
- 普通文件：用户程序、数据文件；
- 目录文件：组织树型目录结构，由目录项组成；
- 特别文件：与硬件设备关联，是用户与设备交互的接口。

### 3. 索引节点（i节点）
#### （1）定义
将文件目录项中除文件名外的信息（属性、物理地址等）存储在i节点中，目录项仅保留文件名和i节点号，减少目录占用空间。

#### （2）磁盘i节点结构
- 核心字段：文件所有者标识（i_uid、i_gid）、文件类型（i_type）、存取许可权（i_mode）、链接计数（i_ilink）、存取时间（i_time）、文件长度（i_size）、地址索引表（i_addr[]）。

### 4. UNIX的索引文件结构
#### （1）UNIX第七版本（i_addr[8]）
- 小型文件（直接索引）：i_addr[0]-i_addr[7]直接记录物理块号，最大容量 8×512B；
- 大型文件（一级间接索引）：i_addr[0]-i_addr[6]记录一级索引表块号，最大容量 7×256×512B；
- 巨型文件（二级间接索引）：i_addr[7]记录二级索引表块号，最大容量（7×256 + 256²）×512B。

<img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107034008324.png" alt="image-20251230215317038" style="zoom: 50%;" />


#### （2）UNIX System V（i_addr[13]）
- 支持直接索引（10个）、一级间接索引（1个）、二级间接索引（1个）、三级间接索引（1个）；
- 最大容量：（10 + 256 + 256² + 256³）×512B，适配更大文件存储。

### 5. UNIX的目录结构
#### （1）目录项结构
- 老版本：16字节，前2字节为i节点号，后14字节为文件名；
- 一个磁盘块（512B）可存储32个目录项。

#### （2）树型目录实现
- 根目录的i节点是文件系统索引区的第一个i节点；

- 打开文件时，从根目录i节点找到根目录文件，逐级匹配路径名，最终获取目标文件的i节点号，再通过i节点的索引表找到数据块。

  <img src="https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107034010394.png" alt="image-20251231021241688" style="zoom:67%;" />

#### （3）文件勾链（共享）
- 多个目录项可指向同一个i节点，通过i_ilink（链接计数）记录共享次数；
- 仅支持非目录文件勾链，删除文件时需当i_ilink减为0才释放i节点和数据块。

### 6. 打开文件机构
为提高文件存取效率，UNIX设置三级数据结构管理打开文件：
- 活动i节点表（主存i节点）：缓存当前使用的磁盘i节点信息；
- 系统打开文件表：记录打开文件的读写标志、引用计数、主存i节点指针、读写位置指针；
- 用户文件描述符表：进程控制块中的数组，每个元素指向系统打开文件表的表项，文件描述符为数组索引。

### 7. 存储空间管理（成组链接法）
#### （1）文件卷结构
- 引导块：存储引导程序；
- 索引节点区：存储所有磁盘i节点；
- 数据区：存储文件数据块；
- 管理块：记录文件系统信息（如总块数、空闲块数、空闲块号栈、空闲i节点号栈）。

#### （2）空闲块管理
- 核心逻辑：将空闲块每100块分为一组（最后一组99块），每组最后一块记录下一组块号，最前一组信息存于管理块的s_free[]；
- 分配：从s_free[]栈顶取块号，栈空时读取下一组块信息；
- 回收：块号压入s_free[]栈，栈满时将当前栈信息写入回收块，重置栈。

## 六、文件存储空间管理
除UNIX的成组链接法外，常用管理方法还有：

### 1. 位示图法
- 核心逻辑：用二进制位表示磁盘块状态，0表示空闲，1表示已分配；
- 优点：占用空间小，可常驻内存，分配和回收效率高；
- 缺点：不适用于大容量磁盘，位示图查找需遍历。

### 2. 空闲块链法
- 核心逻辑：所有空闲块通过链表链接，系统记录链表头指针；
- 优点：实现简单，适应动态分配；
- 缺点：遍历链表开销大，尤其是空闲块较多时。

## 七、文件的共享与安全
### 1. 文件共享
#### （1）定义
多个用户或进程共同使用指定文件，目的是节省存储空间、实现进程间信息交换。

#### （2）共享方式
- 路径名共享：通过不同路径名访问同一文件（如UNIX的勾链）；
- 链接技术：
  - 硬链接：多个目录项指向同一i节点，链接计数递增，删除源文件不影响链接文件；
  - 软链接（符号链接）：创建新文件记录源文件路径名，删除源文件后链接失效。

### 2. 文件安全（保护）
#### （1）定义
防止文件被未授权访问或破坏，授权用户仅能在允许权限内操作。

#### （2）存取权限验证方法
- 访问控制矩阵：以用户和文件为维度，记录每个用户对每个文件的权限；
- 存取控制表：为每个文件建立权限表，记录授权用户及权限；
- 用户权限表：为每个用户建立权限表，记录该用户可访问的文件及权限；
- 口令：文件设置口令，用户输入正确口令方可访问；
- 密码：文件数据加密存储，仅授权用户持有解密密钥，保障数据机密性。


### 3. 加快文件查找的机制
- 当前目录（PWD）：用户指定当前工作目录，文件访问可使用相对路径（如当前目录为`/b`，访问文件`/b/f/j`可简化为`f/j`），减少路径遍历开销；
- 链接技术：通过目录项勾链，直接指向目标文件的目录表目，缩短查找路径。

## 八、文件操作与文件备份
### 1. 常用文件操作命令
| 命令名称 | 功能描述                                                                 |
|----------|--------------------------------------------------------------------------|
| create   | 创建新文件，建立文件目录项和必要的数据结构                               |
| delete   | 从目录中删除文件，回收文件占用的存储空间和i节点                           |
| rename   | 修改文件的符号名，更新目录项中的文件名信息                               |
| open     | 建立用户与文件的逻辑通路，将文件目录项或i节点缓存到主存，返回文件描述符   |
| close    | 切断用户与文件的逻辑通路，释放主存中的文件控制块或缓存的i节点             |
| write    | 将用户数据写入文件（或设备），完成逻辑记录到物理块的映射                 |
| read     | 从文件（或设备）读取数据，将物理块数据转换为用户可识别的逻辑记录         |

#### （2）open与close操作的核心目的
- open：避免每次文件操作都遍历目录，通过缓存文件元信息（如i节点）提高存取效率；
- close：释放主存资源，确保文件数据同步到辅存，避免数据丢失。

### 2. 文件备份
#### （1）定义
为应对软、硬件失效，复制文件数据到备份介质（如磁带、磁盘、远程服务器），保证文件完整性和可恢复性。

#### （2）备份方法
- 周期性转储：按固定周期（如每日、每周）转储所有文件，恢复时可还原到最后一次转储状态；
- 增量性转储：仅转储上次转储后修改过的文件，转储数据量小、耗时短，可频繁执行；
- 发展趋势：动态备份（实时备份文件变化）、远程备份（跨地域存储备份数据，提高灾备可靠性）。

## 九、重点总结
- 文件系统基础（理解）：
  - 文件定义、分类、属性；文件系统的功能与特点；
  - 逻辑结构（流式/记录式）与物理结构（连续/串联/索引）的区别与适用场景；
- 文件目录（掌握）：
  - 目录项核心内容；一级目录与树型目录的优缺点；路径名与当前目录的作用；
- UNIX文件系统（掌握）：
  - i节点结构与索引文件实现（直接/一级/二级/三级间接索引）；
  - 打开文件机构（三级数据结构）；空闲块管理（成组链接法）；
- 文件共享与安全（理解）：
  - 共享方式（硬链接/软链接）；安全保护的权限验证方法；
- 文件操作与备份（理解）：
  - 核心文件操作（open/close/read/write）的功能；
  - 备份的目的与常用方法（周期性/增量性转储）。

## 例题：

1.(课本习题)某系统采用成组链接法来管理系统盘的空闲存储空间， 目前，磁盘的状态如图9.33所示。回答如下问题:

![img](https://gitee.com/ilosyi/typora-image-bed/raw/master/typora/20260107034014192.jpg) 

(1)该磁盘中目前还有多少个空闲盘块?

(2)系统需要给文件F分配3个磁盘块，试给出将被分配出去的磁盘块号。

(3)接着(在创建文件F之后),系统要删除另一个文件，并回收它所占的5个盘块，它们的盘块号依次为700、711、703、788、701, 试给出回收后的盘块链接情况。

### 例题1回答：

---

#### (1) 该磁盘中目前还有多少个空闲盘块?

我们需要将超级块（内存中）和磁盘链表中所有的空闲块加起来。

1. **超级块 (s_free):**

   * 计数为 `2`。
   * 包含块号：`100` (数据块) 和 `200` (当前作为链接块，分配出去后它自己也是一个可用的空闲块)。
   * **小计:** 2 个。

2. **块 200 指向的一组:**

   * 计数为 `100`。
   * 包含：`300` (链接块) 和 `201` ~ `299` (99个数据块)。
   * **小计:** 100 个。

3. **块 300 指向的一组:**

   * 计数为 `100`。
   * 包含：`400` (链接块) 和 `301` ~ `399` (99个数据块)。
   * **小计:** 100 个。

4. **块 400 指向的一组 (最后一组):**

   * 计数为 `100`。
   * 包含：`0` 和 `401` ~ `499`。
   * **注意:** `0` 表示空指针（NULL），不是有效的物理盘块号，不能分配。
   * 有效块为 `401` ~ `499`，共 99 个。
   * **小计:** 99 个。

**总空闲块数计算:**
$$2 + 100 + 100 + 99 = 301$$

**答：该磁盘中目前还有 301 个空闲盘块。**

---

#### (2) 系统需要给文件F分配3个磁盘块，试给出将被分配出去的磁盘块号。

成组链接法的分配遵循 **后进先出 (LIFO)** 的堆栈原则。但在处理链接块时有特殊逻辑。

* **当前状态:** `s_free` 栈中有 `200` (栈底/链接) 和 `100` (栈顶/数据)。计数 Count = 2。
* **分配原则:** 优先分配数据块。当栈中只剩下一个块（链接块）时，先把该块中保存的下一组信息读入超级块 `s_free`，然后再分配该块。

**分配过程：**

1. **分配第 1 个块:**

   * 从 `s_free` 栈顶取出普通数据块。
   * **分配块号:** **100**。
   * **状态变更:** `s_free` 计数变为 1，栈中只剩 `200`。

2. **分配第 2 个块:**

   * `s_free` 计数为 1，剩下的 `200` 是链接块。
   * **操作:** 系统先将块 `200` 中的内容（下一组信息：计数100，数据300, 201...299）读入内存的 `s_free` 中。
   * 现在 `s_free` 充满了新的一组数据，而块 `200` 变为空闲的数据块。
   * **分配块号:** **200**。
   * **状态变更:** `s_free` 计数变为 100（满）。栈顶通常是数组的高地址端（对应图中的底部数据）。按照一般Unix实现，数组顺序通常是 `s_free[0]=300`, `s_free[1]=201` ... `s_free[99]=299`。分配时下标递减。

3. **分配第 3 个块:**

   * 从新的 `s_free` 栈顶取出。新栈的内容是 `300`, `201`...`299`。
   * 栈顶元素（最后入栈的/数组末尾）是 `299`。
   * **分配块号:** **299**。
   * **状态变更:** `s_free` 计数变为 99。

**答：将被分配出去的磁盘块号依次为：100、200、299。**

---

#### (3) 接着，系统要回收5个盘块（700, 711, 703, 788, 701），试给出回收后的盘块链接情况。

回收也是栈操作（入栈）。如果栈满了（达到100），则将当前的栈内容写入新回收的块中，该新块作为新的链接块。

**初始状态（操作(2)之后）:**

* `s_free` 计数: 99。
* `s_free` 内容: `300` (在底部/下标0), `201` ... `298` (当前栈顶)。

**回收过程：**

1. **回收 700:**

   * 栈未满 (99 < 100)。直接入栈。
   * **状态:** 计数 = 100。栈顶变为 700。

2. **回收 711:**

   * 栈已满 (100)。
   * **操作:**

     1. 将当前 `s_free` 中的所有信息（计数100，以及块号 `300, 201...298, 700`）写入到 **块 711** 中。
     2. 清空 `s_free`。
     3. 将 **711** 放入 `s_free` 的第一个位置（链接位）。
     4. 设置 `s_free` 计数 = 1。
   * **状态:** `s_free` 中只有 `711`。

3. **回收 703:**

   * 栈未满。直接入栈。
   * **状态:** 计数 = 2。内容: `711`, `703`。

4. **回收 788:**

   * 栈未满。直接入栈。
   * **状态:** 计数 = 3。内容: `711`, `703`, `788`。

5. **回收 701:**

   * 栈未满。直接入栈。
   * **状态:** 计数 = 4。内容: `711`, `703`, `788`, `701`。

**答：回收后的链接情况如下：**

* **超级块 (s_free) 中：**

  * **空闲块数 (Count):** 4
  * **空闲块号栈:** 依次为 `711`, `703`, `788`, `701`（其中 `711` 是指向下一组的链接块，`701` 是栈顶）。

* **磁盘块 711 中（作为新的一组链接）：**

  * **空闲块数:** 100
  * **空闲块号栈:** 包含原先的 `300` (指向再下一组), `201`...`298`, 以及 `700`。



2.(期末真题|考研真题)文件簇大小为4KB，文件索引结点大小为64B，包含11个地址项，8个直接，1个1级，1个2级，1个
3级，地址项大小为4B.
(1) 最大文件大小，给出表达式即可
(2) 一个图片文件 5600B，磁盘共有 1M 个索引文件簇和 512M 个数据文件簇，最多存多少图片文
件
(3) 文件 F1 大小为 6KB，文件 F2 大小为 40KB，请问两个寻址到最后一个文件簇的时间是否相
同。说明原因。

### 例题2回答：

这是一个关于文件系统索引节点（Inode）机制的计算题。我们需要根据给定的参数一步步分析。

**核心参数梳理：**

* **物理块大小 (Block Size):** $4\text{KB} = 4096\text{B}$
* **地址项大小 (Address Size):** $4\text{B}$
* **每个块能存放的指针数量:** $4096 / 4 = 1024$ 个
* **索引结构:**

  * 8个直接地址
  * 1个一级间接 (指向 1024 个块)
  * 1个二级间接 (指向 $1024^2$ 个块)
  * 1个三级间接 (指向 $1024^3$ 个块)

---

#### (1) 最大文件大小 (给出表达式)

最大文件大小等于所有寻址方式能覆盖的磁盘块总数乘以块大小。

* **直接寻址:** $8$ 个块
* **一级间接:** $1024$ 个块
* **二级间接:** $1024 \times 1024 = 1024^2$ 个块
* **三级间接:** $1024 \times 1024 \times 1024 = 1024^3$ 个块

**表达式如下：**
$$ \text{Max Size} = (8 + 1024 + 1024^2 +\text{Max Size} = (8 + 1024 + 1024^2 + 1024^3) \times 4\text{KB}$$

*(注：如果需要更形式化的写法，1024 可以写成 $\frac{4\text{KB}}{4\text{B}}$)*

---

#### (2) 最多存多少图片文件

我们需要从两个维度的限制条件来考虑：**索引节点（Inode）数量限制** 和 **磁盘数据空间限制**，系统受限于两者的**最小值**（木桶效应）。

**1. 单个文件需求分析：**

* 文件大小：$5600\text{B}$
* 所需数据块：$\lceil 5600 / 4096 \rceil = 2$ 个块 (第一个块存4096B，第二个块存1504B)
* 所需索引节点：1 个

**2. 限制条件分析：**

* **限制 A：索引节点数量 (Inode Limit)**

  * 题目给定共有 1M 个索引文件簇，每个能存4KB/64=64个索引结点
  * 最多可存文件数 = **64M 个**。

* **限制 B：数据空间数量 (Data Block Limit)**

  * 题目给定共有 512M 个数据文件簇。
  * 每个文件占用 2 个簇。
  * 最多可存文件数 = $512\text{M} / 2 = 256\text{M}$ 个。

**3. 结论：**
$\min(64M, 256M) = 64M$
**答：最多存 64M 个图片文件。**
*(虽然磁盘空间绰绰有余，但文件数量被 Inode 总数限制住了。)*

---

#### (3) 寻址到最后一个文件簇的时间是否相同？说明原因。

**答：不相同。F2 会更慢。**

**原因分析：**

我们需要查看两个文件的最后一个块分别落在哪种寻址范围内（直接、一级、二级等）。不同的寻址范围需要的磁盘 I/O 次数不同。

* **直接寻址范围:** $8 \times 4\text{KB} = 32\text{KB}$。

  * 这意味着文件的前 32KB 数据可以通过直接地址项找到。

* **分析文件 F1 (6KB):**

  * $6\text{KB} < 32\text{KB}$。
  * F1 一共占用 2 个块。
  * 它的所有数据（包括最后一个簇）都由 **直接地址项** 管理。
  * **访问过程:** 读取 Inode $\to$ 获取物理块号 $\to$ 访问数据。 (假设 Inode 已在内存，只需 **1次** 磁盘 I/O 访问数据)。

* **分析文件 F2 (40KB):**

  * $40\text{KB} > 32\text{KB}$。
  * F2 一共占用 $\lceil 40/4 \rceil = 10$ 个块。
  * 前 8 个块 (32KB) 存在直接地址项中。
  * 剩余 $40 - 32 = 8\text{KB}$ (即最后 2 个块) 必须存放在 **一级间接索引** 中。
  * **访问过程:** 读取 Inode $\to$ 读取一级索引块 (第一次磁盘 I/O) $\to$ 获取目标物理块号 $\to$ 访问数据 (第二次磁盘 I/O)。
  * **寻址最后一个簇:** 需要通过一级间接寻址，这比直接寻址多了一次读取索引块的操作。

**结论：** F1 使用直接寻址，F2 的最后一个簇使用一级间接寻址。由于 F2 需要额外的磁盘 I/O 来读取索引表，因此 F2 的访问时间更长。


# PKE实验
## 实验文档中的思考题

### **实验 1：Trap / Syscall / Exception / Interrupt（chapter3）**

#### **lab1_1 系统调用**

**思考题 1：**
**为什么陷入内核处理系统调用时要切到每进程的用户内核栈（kstack），而不是用 PKE 内核“自己的栈”？**
**答案：**
不同进程之间需要独立的内核栈来保存进程的现场数据，避免栈数据被不同进程互相覆盖。每个进程使用自己的 `kstack` 来保证内核操作的独立性和安全性。共用全局栈会导致数据竞争和资源共享问题。

**思考题 2：**
**为什么 `handle_syscall` 里要做 `tf->epc += 4`？**
**答案：**
`epc` 保存的是触发异常的指令地址，`ecall` 指令会导致异常。为了防止 `sret` 回到相同的异常地址，必须将 `epc` 加 4，让程序跳到异常指令的下一条指令，避免再次触发异常。

**思考题 3：**
**内核如何得到应用里 `"Hello world!"` 这个字符串的地址？**
**答案：**
字符串地址作为参数传递给系统调用时，内核通过读取用户传入的寄存器中的地址信息（如 `a0` 寄存器）来获取地址。之后内核根据虚拟地址通过用户页表进行映射或直接访问。

---

#### **lab1_2 非法指令异常**

**思考题：**
**为什么这个实验选择在 M 态拦截非法指令，而不是交给 S 态？**
**答案：**
RISC-V 默认将所有异常交给最高权限的 **M 模式（Machine Mode）**。虽然 PKE 内核在启动时调用了 `delegate_traps()` 函数将部分异常（如缺页、断点等）委托给了 **S 模式** 处理，CAUSE_ILLEGAL_INSTRUCTION并没有被包含在委托列表 `exceptions`中，这意味着该异常必须由 **M 模式** 的中断处理程序来捕获和处理，而不是 S 模式。

---

#### **lab1_3 时钟中断**

**思考题 1：**
**为什么不在 M 态把时钟中断“全部做完”，而要接力给 S 态？**
**答案：**
M 态主要负责底层硬件交互和异常处理，时钟中断涉及调度等高层操作，应该交给 S 态来处理，这样可以避免影响到进程调度的正确性，同时让 S 态完成更高层次的任务。

> 这是因为，对于一个操作系统来说，timer事件对它的意义在于，它是标记时间片的重要（甚至是唯一）手段，而将CPU事件分成若干时间片的作用很大程度上是为了做进程的调度（我们将在lab2_3中接触），同时，操作系统的功能大多数是在S态完成的。如果在M态处理时钟中断，虽然说特权级上允许这样的操作，但是处于M态的程序可能并不是非常清楚S态的操作系统的状态。如果贸然采取动作，可能会破坏操作系统本身的设计。

**思考题 2：**
**完成 lab1_3 后，为什么“应用里的死循环”不会导致系统死机？**
**答案：**
因为时钟中断是外部异步事件。即使程序在 U 模式下陷入死循环，硬件定时器依然会周期性触发中断。中断会强制 CPU 陷入内核（S 模式），并在处理函数中通过调度器（如 `rrsched`）剥夺该进程的 CPU 使用权，切换到其他进程执行

#### **关于 ELF 文件与启动**

**思考题 1：helloworld 文件的 ELF 结构中为什么没有出现堆栈（.stack）段？**

  **答案**：栈（Stack）是一个运行时（Runtime）概念，其大小通常在程序加载时由操作系统分配或在运行时动态扩展（如 Lab 2.3），而不是静态地存储在 ELF 文件中。

**思考题2：代理内核起始逻辑地址固定在 0x80000000 的原因？**

  答案**：Spike 模拟器将模拟的内存放置在 `0x80000000` 开始的物理地址空间。将内核逻辑地址设为相同值，可以实现逻辑地址与物理地址的一一对应（直映射），简化内核启动初期的访存逻辑。

---

### **实验 2：Memory / Paging / Page Fault（chapter4）**

#### **lab2_2 堆页分配**

**思考题：**
**`USER_FREE_ADDRESS_START`（4MB）位于用户地址空间的哪个区域？为什么选 4MB？还可以选别的地址吗？**
**答案：**
`USER_FREE_ADDRESS_START` 位于用户堆管理区域，用于存储空闲页地址。选择 4MB 是为了避免与其他常见的段（如代码段、数据段）重叠。可以选其他地址，只要不与现有的地址段冲突，并满足页对齐要求即可。

**思考题 2：**

**在 Sv39 方案中，一个物理页能容纳多少个页表项？VPN[i] 为什么是 9 位？**

**答案：**

一个物理页为 4KB，每个页表项（PTE/PDE）占 8 字节，因此一页可容纳 4*K**B*/8*B*=512 个项。512 正好是 29，因此需要 9 位地址来索引页表内的项。

---

#### **lab2_3 缺页异常与栈增长**

**思考题：**
**缺页异常是否也需要在 M 模式处理？为什么通常交给 S 模式？**
**答案：**
通常不在 M 模式处理缺页异常，因为缺页异常是虚拟内存管理的问题，更适合由 S 模式处理，S 模式负责管理进程的内存空间和地址映射，而 M 模式负责底层硬件的管理。

---

### **实验 3：Process / fork / schedule / wait（chapter5）**

#### 基础知识

**思考题 ：**

**为什么 free_process() 只将进程设为 ZOMBIE 而不立即释放资源？**

 **答案**：因为执行 `exit` 时，内核正运行在该进程的“用户内核栈”上。如果立即释放内存，操作系统当前的执行流将失去栈空间支撑，直接导致系统崩溃。

#### **lab3_1 fork**

**思考题 1：**
**子进程如何“继承”父进程的代码段？为什么不建议简单 `memcpy` 整个代码段？**
**答案：**
子进程继承父进程的代码段是通过共享物理页和映射相同的虚拟地址空间来实现的。直接 `memcpy` 整个代码段不仅会浪费内存，而且会破坏进程间共享代码段的机制。使用共享映射可以节省内存并提高效率。

---

#### **lab3_2 yield**

**思考题 1：**
**若忘记在内核注册 syscall 号，会出现什么典型现象？**
**答案：**
如果没有注册正确的 syscall 号，系统会报错或者返回“未知系统调用”错误。调试时会发现没有正确识别到用户发起的 syscall，导致程序异常终止。

---

### **实验 4：Filesystem / VFS / Path（chapter6）**

#### **lab4_1 文件操作**

**思考题：**
**进程创建时 `pfiles` 是如何初始化的？默认 cwd 是什么？**
**答案：**
进程创建时，`pfiles` 会初始化为一个新分配的结构，其中当前工作目录（`cwd`）默认指向根目录。所有打开的文件表项初始化为空，文件数为 0。

---

#### **lab4_3 硬链接**

**思考题：**
**创建硬链接时，为什么需要“增加 inode 引用计数/链接计数”？**
**答案：**
因为硬链接实际上是指向同一文件的多个路径名，增加 inode 的链接计数确保文件的实际内容只有在所有链接都删除时才会被释放，从而避免意外丢失文件内容。

---



## 模拟题

### 真题


PKE 系统中，基础实验 3-1（fork）里，用户态调用 `fork()` 之后，`do_fork()` 的典型调用链是：
`user/app_naive_fork.c` → `user/user_lib.c` → `kernel/strap_vector.S` → `kernel/strap.c` → `kernel/syscall.c` → （系统调用分发到 fork 对应处理）→ `kernel/process.c: do_fork()`。 

---

#### (1) 为什么处理系统调用时用“用户内核栈（每进程 kstack）”，而不是 PKE 全局内核栈？

**答案要点：**

1. **并发/可重入安全**：系统调用/异常可能在不同进程之间频繁切换；如果所有进程共用一个“全局内核栈”，不同进程在 S 态保存的现场（寄存器、局部变量、返回地址等）会互相覆盖，轻则崩溃，重则产生安全问题。
2. **进程隔离**：每个进程独立的 `kstack` 能把“进入内核后的执行栈”隔离开，避免一个进程影响另一个进程的内核执行现场。PKE 的进程结构里，`kstack` 就是“进入 S 模式后操作系统使用的栈”。
3. **机制上就是这么设计的**：在 `switch_to()` 中，PKE 会把 `proc->kstack` 写进 trapframe 里供 trap 入口使用：`proc->trapframe->kernel_sp = proc->kstack;`，这等于明确规定了“该进程进内核就用自己的内核栈”。

---

#### (2) do_fork 中对子进程“代码段（code segment）”的初始化步骤是什么？

**答案要点（按 do_fork 的逻辑）：**

在 `do_fork()` 里会遍历父进程的 `mapped_info`，对不同段分别处理：trapframe 复制、用户栈复制、堆按页复制等。

**对子进程代码段（`CODE_SEGMENT`）处理的核心步骤是：**

1. **从父进程的 `mapped_info[i]` 得到代码段的虚拟地址 `va` 和页数 `npages`**（注释明确提示“映射信息在 mapped_info 里”）。
2. **找出父进程该代码段虚拟页对应的物理页**（通常通过页表查找/`lookup_pa` 一类手段完成）。
3. **把子进程相同的虚拟地址区间，映射到父进程代码段实际所在的那些物理页上**：

   * **关键点：不复制物理页，只做映射**（题目常考！）
   * 权限应设置为“可读+可执行”（文档提醒注意代码段权限）。
4. **映射完成后，把该段登记进子进程的 `mapped_info` 并更新 `total_mapped_region`**（代码段 case 后半段固定要求“do not delete”）。

总结：**子进程“继承”父进程代码段的方式是共享同一份物理代码页（只映射不拷贝），再在子进程的 mapped_info 中注册该段。**

---

#### (3) S 模式交回 U 模式时执行 `sfence.vma zero,zero` 的作用是什么？

**答案要点：**

* `sfence.vma` 是 RISC-V 的**地址翻译（TLB）刷新指令**。
* `sfence.vma x0, x0`（也常写 `sfence.vma zero, zero`）表示：**不指定 ASID、不指定虚拟地址 → 刷新当前 hart 上所有虚拟地址相关的 TLB 缓存项**。
* 在“从 S 返回 U”这一刻，内核往往刚刚：

  1. 切换/设置了 `satp`（换页表，准备让用户态用自己的页表）；或
  2. 修改了页表映射（例如 fork/mmap/换栈等）。
     如果不做 `sfence.vma`，CPU 可能继续使用旧的 TLB 缓存，导致**用旧映射访问**（轻则跑飞/页故障，重则越权访问）。

所以它的作用可以写成考试标准句：

> **确保页表更新或 satp 切换后，TLB 中的旧地址翻译不会被继续使用，使 U 模式下的地址翻译严格按最新页表生效。**

---



### Gemini生成的模拟题

#### **实验一：系统调用、异常和外部中断**

**【模拟题 1-1】系统调用（Lab 1-1）**
在 `handle_syscall` 处理流程中：
(1) 结合 RISC-V 指令集原理，解释执行 `tf->epc += 4` 的具体原因。
(2) **实验逻辑**：当内核完成 `do_syscall` 调用后，应该如何处理返回值以确保用户程序能正确接收？请描述数据桥接的具体动作。
**参考答案：**
(1) `ecall` 是同步异常，返回地址默认指向 `ecall` 本身。若不加 4 跳过该指令，返回用户态后会无限重复执行 `ecall`。
(2) 将 `do_syscall` 的返回值存入中断帧的 `tf->regs.a0`。这样内核恢复现场返回用户态时，用户程序的 `a0` 寄存器就包含了执行结果。

**【模拟题 1-2】异常处理（Lab 1-2）**
(1) 查阅 `minit.c` 中的 `delegate_traps()`，为什么非法指令异常（`CAUSE_ILLEGAL_INSTRUCTION`）会被 M 模式捕获而非 S 模式？
(2) **实验内容**：在 M 态处理函数 `handle_mtrap` 中，目前的处理方式是调用 `panic`。在实验中，你将其替换为什么函数来安全地终止违规进程？
**参考答案：**
(1) 该异常未包含在 `delegate_traps` 的委托列表中，且在 Spike 平台上，此类底层或致命异常必须由最高特权级（M 模式）拦截。
(2) 替换为 `handle_illegal_instruction()`。

**【模拟题 1-3】中断处理（Lab 1-3）**
(1) 简述时钟中断从 M 模式触发后，是如何“接力”到 S 模式被 `handle_mtimer_trap` 处理的。
(2) **实验逻辑**：在 `handle_mtimer_trap` 中，如果不清除 `sip` 寄存器中的 `SIP_SSIP` 位，会出现什么后果？
**参考答案：**
(1) M 态捕获硬件中断后，通过设置 `sip` 寄存器的 `SIP_SSIP` 位向 S 态发送软中断信号，模拟 S 态时钟中断。
(2) 发生死循环中断。因为挂起标志未清除，CPU 会认为中断未处理完，返回后立即再次进入中断，程序无法继续运行。

---

#### **实验二：内存管理**

**【模拟题 2-1】虚实地址转换（Lab 2-1）**
(1) 在 Sv39 方案中，为什么 VPN[i] 被设计为 9 位？
(2) **实验逻辑**：补全 `user_va_to_pa` 时，如何利用 `page_walk` 获取物理地址？请写出从 PTE 计算 PA 的逻辑。
**参考答案：**
(1) 物理页为 4KB，PTE 占 8B，每页能容纳 512 ($2^9$) 个页表项，故需 9 位索引。
(2) 调用 `page_walk` 找到 PTE；若有效，物理地址 PA = (PTE 中的 PPN << 12) + (VA & 0xFFF)。

**【模拟题 2-2】内存分配与回收（Lab 2-2）**
(1) PKE 中进程动态分配的逻辑地址起始于 4MB（`USER_FREE_ADDRESS_START`），这样设计的目的是什么？
(2) **实验逻辑**：在 `user_vm_unmap(..., free)` 中，当 `free` 参数为 1 时，内核应执行哪两个核心步骤？
**参考答案：**
(1) 为了将堆空间与低地址的代码段和高地址的栈隔离，防止地址冲突。
(2) 1. 获取 PTE 中的物理页地址并调用 `free_page` 释放物理内存；2. 将该 PTE 置零以断开虚实映射。

**【模拟题 2-3】缺页异常（Lab 2-3）**
(1) 什么是“按需分页（Demand Paging）”？
(2) **实验逻辑**：当递归程序触发 `CAUSE_STORE_PAGE_FAULT` 时，内核应执行哪些步骤来扩充栈空间？
**参考答案：**
(1) 仅在程序访问未映射地址触发异常时才分配物理内存的机制。
(2) 1. 从 `stval` 获取缺页地址；2. `alloc_page` 分配新物理页；3. `user_vm_map` 将缺页地址所在的整个页面映射到新物理页。

---

#### **实验三：进程管理**

**【模拟题 3-1】进程创建（Lab 3-1）**
(1) 在 `do_fork` 中，为什么栈段（`STACK_SEGMENT`）必须深拷贝而代码段可以映射？
(2) **实验逻辑**：请列出子进程处理代码段时的四个初始化步骤。
**参考答案：**
(1) 栈段可写且每个进程私有；代码段通常是只读的，共享物理页可以节省内存并加快 fork。
(2) 1. 找到父进程代码段位置；2. 找到对应物理地址；3. 在子进程页表建立相同映射；4. 权限设为可读可执行。

**【模拟题 3-2】进程 Yield（Lab 3-2）**
(1) 进程执行 `yield()` 时，其状态（`status`）发生了怎样的转换？
(2) **实验逻辑**：在 `do_syscall` 中忘记注册 `SYS_user_yield` 分支会导致什么现象？为什么？
**参考答案：**
(1) 从 `RUNNING` 变为 `READY`。
(2) 内核会触发 `panic` 打印 "Unknown syscall"，因为分发器匹配不到 case 会滑入 default 分支并认为这是非法请求。

**【模拟题 3-3】循环轮转调度（Lab 3-3）**
(1) PKE 中定义的时间片长度（`TIME_SLICE_LEN`）是多少个 ticks？
(2) **实验逻辑**：为什么必须在 `handle_mtimer_trap` 末尾显式调用 `rrsched()`？如果不调用，系统调度会变成什么模式？
**参考答案：**
(1) 2 个 ticks。
(2) 因为中断处理完默认返回原进程，必须调用 `rrsched` 检查并强制剥夺 CPU 才能实现抢占。不调用会导致系统退化为先来先服务（FCFS）。

---

#### **实验四：文件系统**

**【模拟题 4-1】文件操作（Lab 4-1）**
(1) RFS 创建新文件时，`rfs_create` 必须初始化磁盘索引节点（`dinode`）。其中 `nlinks` 的初始值为何为 1？
(2) **实验逻辑**：在 `rfs_create` 中，新文件的 `size` 和 `type` 字段应分别初始化为何值？
**参考答案：**
(1) 因为创建文件后，其父目录中已经有一个目录项指向了该 Inode。
(2) `size` 初始化为 0；`type` 初始化为普通文件（`R_FILE`）。

**【模拟题 4-2】目录文件（Lab 4-2）**
(1) RFS 为了提高读取效率，在打开目录时使用了什么缓存机制？其原理是什么？
(2) **实验逻辑**：在补全 `rfs_readdir` 时，你需要将 `p_direntry` 中的哪些信息复制到 VFS 的 `dir` 结构体中？
**参考答案：**
(1) 目录缓存（`dir_cache`）。在 `opendir` 时将整个目录的数据块预读入内存，后续 `readdir` 直接在内存中偏移读取，减少磁盘 I/O。
(2) 复制文件名（`name`）和 Inode 编号（`inum`）。

**【模拟题 4-3】硬链接（Lab 4-3）**
(1) 硬链接（Hard Link）的本质是什么？为什么删除一个硬链接不一定会释放文件占用的磁盘块？
(2) **实验逻辑**：实现 `rfs_link` 需要哪三个物理步骤？
**参考答案：**
(1) 本质是多个文件名指向同一个 Inode 编号。只有当 Inode 的 `nlinks` 减为 0 时，系统才会真正释放物理盘块。
(2) 1. 目标 Inode 的 `nlinks` 加 1；2. 在父目录添加新的目录项（新文件名->原 Inode 号）；3. 将更新后的 Inode 写回磁盘。



---

### GPT生成的模拟题

#### 实验 1：系统调用、异常和（外部）中断

##### Lab1_1（系统调用）模拟题

**题干（给调用链）**：用户态执行 `ecall` 后进入 `smode_trap_vector`，保存寄存器到 trapframe，切换到 `p->trapframe->kernel_sp`，跳转到 `smode_trap_handler()`，最后 `return_to_user()` 恢复寄存器并 `sret`。

**问题**

1. 画出从 U→S→U 的关键状态变化：至少写出 **sepc/scause/sscratch/sp** 在链路中的用途。
2. 为什么 trap 入口要把 `sp` 切到“用户进程自带的内核栈”？如果不切，最容易出现哪两类 bug？
3. 如果系统调用号放在 a0/a7（取决于你们约定），在保存/恢复过程中最关键的“不能出错点”是什么？为什么？

**参考答案要点**

1. `sepc` 记录返回用户态的 PC；`scause` 指明 trap 原因（ecall/异常/中断）；`sscratch` 常用来暂存 trapframe 指针或临时寄存器；`sp` 在 trap 入口从“内核全局栈”切到“该进程 kernel_sp”（进程私有）。
2. 因为系统调用/异常处理会发生**函数调用、局部变量压栈、嵌套 trap**等；若共用全局栈：

   * 多进程/多次 trap 会**互相覆盖栈帧**（数据破坏、返回地址错）
   * 隔离性差：一个进程的内核执行痕迹可能被另一个进程“踩到”甚至利用
3. 关键点是：**系统调用号与参数寄存器**在“保存上下文/切栈/进入 C handler”的过程中不能被意外覆盖；一旦覆盖，分发到错误 syscall 或参数错会导致“看似随机”的异常行为。

---

##### Lab1_2（异常处理）模拟题

**题干（给现象）**：用户程序执行一条非法指令触发异常，trap 进入内核后你读取到：`scause=Illegal Instruction`，`sepc=0x...`，`stval=0x0`。

**问题**

1. 解释 `sepc`、`stval` 在异常诊断中的分工：各自“最常拿来干什么”。
2. 你要让系统“跳过”这条非法指令继续执行（仅用于实验），应如何修改现场？写出核心逻辑。
3. 若你不修改 `sepc` 就直接 `sret`，会发生什么？为什么这是“经典死循环异常”？

**参考答案要点**

1. `sepc` 是异常发生时的 PC，用于决定返回后从哪里继续；`stval` 通常提供与异常相关的地址/信息（如页故障地址），非法指令时可能无有效地址。
2. 跳过一条指令：把 trapframe 里的 `epc/sepc` 增加一个指令长度（RISC-V 通常 4 字节；若支持压缩指令需判断长度），然后返回用户态。
3. 不改 `sepc`：返回后仍执行同一条非法指令→再次 trap→无限循环。

---

##### Lab1_3（外部中断）模拟题

**题干（给片段）**：你在 timer/外部中断处理函数里做了“打印一行日志然后返回”。

**问题**

1. 为什么中断处理必须区分“**确认/清除 pending**”与“仅仅返回”？如果不确认会怎样？
2. 中断与异常在“发生时机/是否可屏蔽/是否有确定触发指令”上有何区别？请结合 `scause` 描述。
3. 如果你在中断里操作就绪队列/进程状态，为什么通常要临界区（关中断或自旋锁）？说明一个竞态场景。

**参考答案要点**

1. 不清 pending：硬件/CLINT/PLIC 仍认为中断未处理，返回后立刻再次进入中断，形成“中断风暴”。
2. 异常是同步的（由当前指令触发），中断是异步的（外设/计时器触发）；`scause` 的最高位常用来区分 Interrupt vs Exception。
3. 竞态例子：中断到来时正好在修改队列指针，若处理函数也改同一结构，会破坏链表导致丢进程/循环链。

---

#### 实验 2：内存管理（分页/映射/页故障/用户态内存）

##### Lab2_1（建立映射/页表）模拟题

**题干（给过程）**：你实现 `user_vm_map(pagetable, va, size, pa, perm)`，要求支持按页映射。

**问题**

1. “把一段虚拟地址映射到物理地址”的核心步骤拆成 3~4 步写出来（要体现页表 walk/分配中间页表/写 PTE）。
2. 为什么页表项权限要区分 R/W/X？如果把代码段误设成 W，会带来什么后果（至少两点：安全/正确性）？
3. 映射完成后，哪些情况下必须做 TLB 同步（例如 `sfence.vma`）？为什么？

**参考答案要点**

1. 典型逻辑：对每个页：计算 VPN→walk 到最后一级；若中间页表不存在则分配并填上指针 PTE；最后一级写 leaf PTE（PPN+权限+V）。
2. 代码段可写会允许自修改代码/注入 shellcode；也可能破坏只读共享导致多个进程互相影响。
3. 当你修改了当前地址空间正在使用的页表映射，或切换了 satp 指向新页表时，需要用 `sfence.vma` 保证翻译缓存不继续使用旧条目。

---

##### Lab2_2（页分配/释放）模拟题

**题干（给片段）**：你用空闲链表实现 `alloc_page()`/`free_page(pa)`。

**问题**

1. 为什么 `free_page` 不能“无脑把 pa 插回链表”？至少说出两个必须检查/保证的条件。
2. 解释“重复释放 double free”在空闲链表里会造成什么结构性破坏，并给出一种最小代价的检测办法。
3. 如果你把“页表页”和“普通数据页”混在同一条 free list，可能出现什么调试地狱？为什么？

**参考答案要点**

1. pa 必须页对齐、在可管理物理内存范围内；且该页当前确实不再被任何映射/引用。
2. double free 会让同一节点出现多次，链表可能形成环或导致两个分配者拿到同一物理页；检测：释放时写入 magic、或维护 bitmap/引用计数。
3. 页表页被当成普通页返回后可能被写垃圾数据，下一次 walk 页表直接崩；且症状通常“延迟爆炸”，极难定位。

---

##### Lab2_3（页故障/按需分配）模拟题

**题干（给现象）**：用户访问堆区某地址触发 `store page fault`，`stval` 给出 fault VA。你希望实现“按需分配一页并继续执行”。

**问题**

1. 写出页故障处理的核心逻辑：从 `stval` 到最终让用户态继续执行，中间必须做哪些事？
2. 为什么要把 fault VA 向下对齐到页边界？不对齐会怎样？
3. 分配并建立映射后，为什么通常还要做一次地址翻译同步（TLB 相关）？

**参考答案要点**

1. 读取 stval→页对齐→判断是否在合法可增长区间（如 heap/stack）→alloc_page→建立 PTE（R/W 等）→必要时 `sfence.vma`→返回用户态。
2. 页表以页为粒度；不对齐会导致同一页内不同地址重复建映射或覆盖错误 PTE。
3. CPU 可能缓存了“该 VA 无映射”的翻译结果或旧条目，不同步可能仍然 fault 或访问旧映射。

---

#### 实验 3：进程管理（fork / yield / 调度）

##### Lab3_1（fork）模拟题

**题干（给伪代码）**：`do_fork(parent)` 遍历 `parent->mapped_info[i]`，按段类型处理：

* STACK/CONTEXT：复制页面内容到子进程新分配页
* CODE：子进程建立“相同 VA → **同一物理页**”映射，权限 RX
* DATA：复制或（若挑战）COW

**问题**

1. 详细写出“处理 CODE 段”的实现逻辑（按步骤写：找 VA 范围→找父 PTE/PA→在子页表建映射→设权限）。
2. 为什么 CODE 段适合共享同一物理页？反过来，为什么 DATA/STACK 通常不能这么做？
3. fork 返回值如何做到“父进程得到 child_pid，子进程得到 0”？你会修改哪一份 trapframe/寄存器现场？

**参考答案要点**

1. 步骤化答案（你示例里的那种写法就对）：

   * 找父进程代码段在虚拟地址空间中的范围（由 mapped_info 标记）
   * 对每个虚拟页：walk 父页表得到 PA
   * 在子进程页表中建立同 VA→同 PA 映射
   * 权限设置为可读可执行（RX），避免写 ([GitHub][3])
2. CODE 通常只读且可被多进程共享，节省内存；DATA/STACK 会写，若共享会互相污染（除非用 COW）。
3. 在创建子进程时，复制父 trapframe 后：把子 trapframe 的返回寄存器设为 0；父路径把返回值设为 child_pid（或直接 do_fork 返回给父）。trapframe/上下文复制的意义就是把父执行现场传给子。 ([Gitee][4])

---

##### Lab3_2（yield）模拟题

**题干（给调用链）**：用户调用 `sys_yield()` → 内核把当前进程从 RUNNING 变 READY，插回就绪队列 → 调用 `schedule()` 选择下一个进程 → `switch_to(next)`。

**问题**

1. 为什么 yield 必须“保存当前上下文”后才能切换？上下文最关键包含哪两类信息？
2. “把自己插回就绪队列”这一步，为什么要发生在 schedule 之前？如果顺序反了会怎样？
3. 如果系统只有一个进程，yield 的正确行为应该是什么？（给出合理解释，不要一句话）

**参考答案要点**

1. 否则下次被调度回来时寄存器/pc/sp 都不对；上下文至少包括通用寄存器+sepc（或 trapframe）+内核栈相关状态。
2. 顺序反了：schedule 可能认为当前不在队列里导致丢失，或选到自己但状态不一致；正确做法是先维护好队列/状态再挑下一个。
3. 只有一个进程时，yield 可能“看似无事发生”：它把自己从 RUNNING→READY→又被选中→RUNNING；关键是状态转换与上下文保存/恢复仍需自洽。

---

##### Lab3_3（循环轮转调度 RR）模拟题

**题干（给现象）**：你实现 time slice=K，每次 timer 中断 `tick_count++`，当 `tick_count==K` 触发抢占：把当前进程放到队尾并调度下一个。

**问题**

1. RR 的“公平性”来自哪个队列不变量？用一句话描述该不变量。
2. 为什么抢占调度通常发生在 timer 中断而不是普通函数调用点？这对“响应性”意味着什么？
3. 说明一个必须做临界区保护的地方：在中断里移动队列指针时，如果不断中断会发生什么？

**参考答案要点**

1. 不变量：就绪队列按“到达队列的先后”轮流取头放尾，且每个进程最多连续运行一个时间片。
2. timer 中断提供强制性，让 CPU 不会被某个进程无限占用；响应性更强（不会等到进程自愿 yield）。
3. 队列操作若可重入：链表指针可能被打断修改，造成断链/环/丢节点，最终表现为“某些进程永远不再运行”。

---

#### 实验 4：文件系统（open/read/write/目录/缓存等）

##### Lab4_1（基础文件读写）模拟题

**题干（给片段）**：实现 `sys_open/sys_read/sys_write/sys_close`，内核维护 `fd -> file` 表，file 指向 inode/offset。

**问题**

1. 为什么需要“每进程 fd 表”与“全局 file 对象/引用计数”分层？只用一个会有什么问题？
2. `read(fd, buf, n)` 的核心逻辑拆成 4 步（至少包含：权限检查、定位 offset、拷贝到用户、更新 offset）。
3. 如果写入时不更新 offset，会出现什么可观测现象？这类 bug 为什么很隐蔽？

**参考答案要点**

1. fd 是进程私有的句柄；file/inode 是可共享的底层对象（多个进程/dup 共享）；否则会导致关闭一个 fd 把别人也关掉或资源泄漏。
2. 检查 fd 合法与读权限→拿到 file/inode→按 offset 找到数据块→拷贝到用户 buf→offset += 实际读到字节数。
3. 现象：连续读/写总是从同一位置开始（重复数据/覆盖文件头）；隐蔽在于单次调用看起来正常，只有连续操作才暴露。

---

##### Lab4_2（目录与路径解析）模拟题

**题干（给过程）**：实现 `open("/a/b/c", ...)` 需要逐级解析目录项。

**问题**

1. 写出路径解析的循环逻辑（伪代码级别即可）：如何从根目录 inode 一步步走到目标 inode？
2. 为什么目录也要用 inode（或类似结构）表示？它和普通文件在“数据内容含义”上最大区别是什么？
3. 如果路径解析没有处理 “.” 和 “..”，会导致哪些实际问题？举 2 个例子。

**参考答案要点**

1. 从 root inode 开始，按 “/” 切分组件；对每个组件：在当前目录的数据块里查目录项→得到下一 inode→继续；最后返回目标 inode。
2. 目录本质是“名字→inode号”的映射表，数据内容是目录项结构数组；普通文件的数据内容是用户字节流。
3. 例：`../x` 无法访问父目录文件；`./a` 与 `a` 行为不一致，很多程序会出错。

---

##### Lab4_3（缓存/一致性/写回策略）模拟题

**题干（给现象）**：你实现块缓存（buffer cache）。读路径：先查 cache，miss 才读盘；写路径：改 cache 并标记 dirty，稍后写回。

**问题**

1. 为什么需要缓存？分别从“性能”和“抽象复杂度”解释一次。
2. dirty 写回策略如果设计不当，会引入哪两类典型问题？（提示：一致性、崩溃恢复）
3. 设计一个最小正确性规则：什么时候必须强制把 dirty 写回磁盘（至少说出一个场景）？

**参考答案要点**

1. 性能：磁盘/设备慢，缓存命中可大幅减少 I/O；复杂度：统一在 cache 层做块对齐、合并小写、重复读共享等。
2. 一致性：读到旧数据/并发覆盖；崩溃恢复：没落盘的数据丢失或元数据半更新导致文件系统损坏。
3. 场景：更新关键元数据（如目录项/inode 分配位图）后，在返回成功给用户之前需要保证必要的写回顺序（最小化“返回成功但实际没落盘”的风险）。

---
